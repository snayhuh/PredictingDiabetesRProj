{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# United States Digital Corps Project-Based Assessment\n",
    "\n",
    "### Track: Data Science\n",
    "\n",
    "``` r\n",
    "knitr::opts_chunk$set(echo = TRUE)\n",
    "### Importing libraries \n",
    "library(dplyr, warn.conflicts = FALSE)\n",
    "library(tidyr)\n",
    "library(tidyverse)\n",
    "```\n",
    "\n",
    "    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n",
    "    ## ✔ ggplot2 3.4.0     ✔ purrr   1.0.0\n",
    "    ## ✔ tibble  3.1.8     ✔ stringr 1.5.0\n",
    "    ## ✔ readr   2.1.3     ✔ forcats 0.5.2\n",
    "    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
    "    ## ✖ dplyr::filter() masks stats::filter()\n",
    "    ## ✖ dplyr::lag()    masks stats::lag()\n",
    "\n",
    "``` r\n",
    "library(tidylog, warn.conflicts = FALSE)\n",
    "library(visdat)\n",
    "library(naniar)\n",
    "library(cdlTools)\n",
    "library(pROC)\n",
    "```\n",
    "\n",
    "    ## Type 'citation(\"pROC\")' for a citation.\n",
    "    ## \n",
    "    ## Attaching package: 'pROC'\n",
    "    ## \n",
    "    ## The following objects are masked from 'package:stats':\n",
    "    ## \n",
    "    ##     cov, smooth, var\n",
    "\n",
    "``` r\n",
    "library(caret)\n",
    "```\n",
    "\n",
    "    ## Loading required package: lattice\n",
    "    ## \n",
    "    ## Attaching package: 'caret'\n",
    "    ## \n",
    "    ## The following object is masked from 'package:purrr':\n",
    "    ## \n",
    "    ##     lift\n",
    "\n",
    "``` r\n",
    "library(e1071)\n",
    "library(Boruta)\n",
    "library(Rcpp)\n",
    "library(randomForest)\n",
    "```\n",
    "\n",
    "    ## randomForest 4.7-1.1\n",
    "    ## Type rfNews() to see new features/changes/bug fixes.\n",
    "    ## \n",
    "    ## Attaching package: 'randomForest'\n",
    "    ## \n",
    "    ## The following object is masked from 'package:ggplot2':\n",
    "    ## \n",
    "    ##     margin\n",
    "    ## \n",
    "    ## The following object is masked from 'package:dplyr':\n",
    "    ## \n",
    "    ##     combine\n",
    "\n",
    "``` r\n",
    "library(ROSE)\n",
    "```\n",
    "\n",
    "    ## Loaded ROSE 0.0-4\n",
    "\n",
    "``` r\n",
    "library(ggcorrplot)\n",
    "library(party)\n",
    "```\n",
    "\n",
    "    ## Loading required package: grid\n",
    "    ## Loading required package: mvtnorm\n",
    "    ## Loading required package: modeltools\n",
    "    ## Loading required package: stats4\n",
    "    ## Loading required package: strucchange\n",
    "    ## Loading required package: zoo\n",
    "    ## \n",
    "    ## Attaching package: 'zoo'\n",
    "    ## \n",
    "    ## The following objects are masked from 'package:base':\n",
    "    ## \n",
    "    ##     as.Date, as.Date.numeric\n",
    "    ## \n",
    "    ## Loading required package: sandwich\n",
    "    ## \n",
    "    ## Attaching package: 'strucchange'\n",
    "    ## \n",
    "    ## The following object is masked from 'package:stringr':\n",
    "    ## \n",
    "    ##     boundary\n",
    "\n",
    "``` r\n",
    "library(gridExtra)\n",
    "```\n",
    "\n",
    "    ## \n",
    "    ## Attaching package: 'gridExtra'\n",
    "    ## \n",
    "    ## The following object is masked from 'package:randomForest':\n",
    "    ## \n",
    "    ##     combine\n",
    "    ## \n",
    "    ## The following object is masked from 'package:dplyr':\n",
    "    ## \n",
    "    ##     combine\n",
    "\n",
    "``` r\n",
    "library(rpart)\n",
    "library(rpart.plot)\n",
    "library(moments)\n",
    "```\n",
    "\n",
    "    ## \n",
    "    ## Attaching package: 'moments'\n",
    "    ## \n",
    "    ## The following objects are masked from 'package:e1071':\n",
    "    ## \n",
    "    ##     kurtosis, moment, skewness\n",
    "\n",
    "# Section 1: Cleaning/EDA\n",
    "\n",
    "## Importing and Merging Data\n",
    "\n",
    "``` r\n",
    "numeric <- read_csv(\"Data/data_numeric.csv\", show_col_types = T)\n",
    "```\n",
    "\n",
    "    ## Rows: 5000 Columns: 6\n",
    "    ## ── Column specification ────────────────────────────────────────────────────────\n",
    "    ## Delimiter: \",\"\n",
    "    ## dbl (6): PERSONID, DIABETE3, NUMADULT, CHILDREN, WEIGHT2, DRVISITS\n",
    "    ## \n",
    "    ## ℹ Use `spec()` to retrieve the full column specification for this data.\n",
    "    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
    "\n",
    "``` r\n",
    "spec(numeric)\n",
    "```\n",
    "\n",
    "    ## cols(\n",
    "    ##   PERSONID = col_double(),\n",
    "    ##   DIABETE3 = col_double(),\n",
    "    ##   NUMADULT = col_double(),\n",
    "    ##   CHILDREN = col_double(),\n",
    "    ##   WEIGHT2 = col_double(),\n",
    "    ##   DRVISITS = col_double()\n",
    "    ## )\n",
    "\n",
    "``` r\n",
    "categorical <- read_csv(\"Data/data_categorical.csv\", show_col_types = T)\n",
    "```\n",
    "\n",
    "    ## New names:\n",
    "    ## Rows: 5000 Columns: 23\n",
    "    ## ── Column specification\n",
    "    ## ──────────────────────────────────────────────────────── Delimiter: \",\" dbl\n",
    "    ## (23): PERSONID, DIABETE3...2, _RACE, MSCODE, FLUSHOT6, EMPLOY1, SEX, MAR...\n",
    "    ## ℹ Use `spec()` to retrieve the full column specification for this data. ℹ\n",
    "    ## Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
    "    ## • `DIABETE3` -> `DIABETE3...2`\n",
    "    ## • `MARITAL` -> `MARITAL...8`\n",
    "    ## • `DIABETE3` -> `DIABETE3...20`\n",
    "    ## • `MARITAL` -> `MARITAL...23`\n",
    "\n",
    "``` r\n",
    "spec(categorical)\n",
    "```\n",
    "\n",
    "    ## cols(\n",
    "    ##   PERSONID = col_double(),\n",
    "    ##   DIABETE3...2 = col_double(),\n",
    "    ##   `_RACE` = col_double(),\n",
    "    ##   MSCODE = col_double(),\n",
    "    ##   FLUSHOT6 = col_double(),\n",
    "    ##   EMPLOY1 = col_double(),\n",
    "    ##   SEX = col_double(),\n",
    "    ##   MARITAL...8 = col_double(),\n",
    "    ##   CVDCRHD4 = col_double(),\n",
    "    ##   HLTHCVR1 = col_double(),\n",
    "    ##   CHCKIDNY = col_double(),\n",
    "    ##   USEEQUIP = col_double(),\n",
    "    ##   `_TOTINDA` = col_double(),\n",
    "    ##   ADDEPEV2 = col_double(),\n",
    "    ##   RENTHOM1 = col_double(),\n",
    "    ##   EXERANY2 = col_double(),\n",
    "    ##   BLIND = col_double(),\n",
    "    ##   DECIDE = col_double(),\n",
    "    ##   HLTHPLN1 = col_double(),\n",
    "    ##   DIABETE3...20 = col_double(),\n",
    "    ##   `_STATE` = col_double(),\n",
    "    ##   ASTHMA3 = col_double(),\n",
    "    ##   MARITAL...23 = col_double()\n",
    "    ## )\n",
    "\n",
    "``` r\n",
    "ordinal <- read_csv(\"Data/data_ordinal.csv\", show_col_types = T)\n",
    "```\n",
    "\n",
    "    ## Rows: 5000 Columns: 11\n",
    "    ## ── Column specification ────────────────────────────────────────────────────────\n",
    "    ## Delimiter: \",\"\n",
    "    ## dbl (11): PERSONID, DIABETE3, GENHLTH, _AGEG5YR, _BMI5CAT, CHECKUP1, INCOME2...\n",
    "    ## \n",
    "    ## ℹ Use `spec()` to retrieve the full column specification for this data.\n",
    "    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
    "\n",
    "``` r\n",
    "spec(ordinal)\n",
    "```\n",
    "\n",
    "    ## cols(\n",
    "    ##   PERSONID = col_double(),\n",
    "    ##   DIABETE3 = col_double(),\n",
    "    ##   GENHLTH = col_double(),\n",
    "    ##   `_AGEG5YR` = col_double(),\n",
    "    ##   `_BMI5CAT` = col_double(),\n",
    "    ##   CHECKUP1 = col_double(),\n",
    "    ##   INCOME2 = col_double(),\n",
    "    ##   `_EDUCAG` = col_double(),\n",
    "    ##   SLEPTIM1 = col_double(),\n",
    "    ##   MENTHLTH = col_double(),\n",
    "    ##   `_SMOKER3` = col_double()\n",
    "    ## )\n",
    "\n",
    "``` r\n",
    "num_ord <- left_join(numeric, ordinal, \"PERSONID\")\n",
    "```\n",
    "\n",
    "    ## left_join: added 11 columns (DIABETE3.x, DIABETE3.y, GENHLTH, _AGEG5YR, _BMI5CAT, …)\n",
    "    ##            > rows only in x       0\n",
    "    ##            > rows only in y  (    0)\n",
    "    ##            > matched rows     5,000\n",
    "    ##            >                 =======\n",
    "    ##            > rows total       5,000\n",
    "\n",
    "``` r\n",
    "num_ord_cat <- left_join(num_ord, categorical, \"PERSONID\")\n",
    "```\n",
    "\n",
    "    ## left_join: added 22 columns (DIABETE3...2, _RACE, MSCODE, FLUSHOT6, EMPLOY1, …)\n",
    "    ##            > rows only in x       0\n",
    "    ##            > rows only in y  (    0)\n",
    "    ##            > matched rows     5,000\n",
    "    ##            >                 =======\n",
    "    ##            > rows total       5,000\n",
    "\n",
    "``` r\n",
    "spec(num_ord_cat)\n",
    "```\n",
    "\n",
    "    ## cols(\n",
    "    ##   PERSONID = col_double(),\n",
    "    ##   DIABETE3 = col_double(),\n",
    "    ##   NUMADULT = col_double(),\n",
    "    ##   CHILDREN = col_double(),\n",
    "    ##   WEIGHT2 = col_double(),\n",
    "    ##   DRVISITS = col_double()\n",
    "    ## )\n",
    "\n",
    "# Section 2: Cleaning and quality-checking data\n",
    "\n",
    "## Run data quality checks on columns that look to be identical\n",
    "\n",
    "``` r\n",
    "data1 <- num_ord_cat %>%\n",
    "  select(starts_with(\"DIABET\") | starts_with(\"MARITAL\")) %>%\n",
    "  mutate(DIABET3_diff = ifelse(DIABETE3.x == DIABETE3.y & \n",
    "                                 DIABETE3.x == `DIABETE3...2` &\n",
    "                                 DIABETE3.x == `DIABETE3...20`, 0, 1)) %>%\n",
    "  ## There are 10 NA values in the marital difference variable-- want to see if they are missing for the same observations\n",
    "  mutate(MARITAL_DIFF = ifelse((`MARITAL...8` == `MARITAL...23`) | \n",
    "                                 (is.na(`MARITAL...8`) & is.na(`MARITAL...23`)), 0 ,1)) \n",
    "```\n",
    "\n",
    "    ## select: dropped 32 variables (PERSONID, NUMADULT, CHILDREN, WEIGHT2, DRVISITS, …)\n",
    "\n",
    "    ## mutate: new variable 'DIABET3_diff' (double) with one unique value and 0% NA\n",
    "\n",
    "    ## mutate: new variable 'MARITAL_DIFF' (double) with one unique value and 0% NA\n",
    "\n",
    "## Take out duplicate columns and clean up variable names using janitor\n",
    "\n",
    "``` r\n",
    "data2 <- num_ord_cat %>%\n",
    "  select(-c(DIABETE3.y, `DIABETE3...2`, `DIABETE3...20`, `MARITAL...8`)) %>%\n",
    "  janitor::clean_names()\n",
    "```\n",
    "\n",
    "    ## select: dropped 4 variables (DIABETE3.y, DIABETE3...2, MARITAL...8, DIABETE3...20)\n",
    "\n",
    "## Account for NA and 0 values in data as provided by data documentation\n",
    "\n",
    "``` r\n",
    "data3 <- data2 %>%\n",
    "  replace_with_na(replace = list(weight2 = c(9999, 7777),\n",
    "                                 children = 99, \n",
    "                                 drvisits = c(77, 99),\n",
    "                                 income2 = c(77, 99),\n",
    "                                 checkup1 = c(7, 9), \n",
    "                                 sleptim1 = c(77, 99), \n",
    "                                 menthlth = c(77, 99), \n",
    "                                 diabete3_x = c(7, 9), \n",
    "                                 race = c(6, 9), \n",
    "                                 flushot6 = c(7, 9), \n",
    "                                 employ1 = 9, \n",
    "                                 marital_23 = 9, \n",
    "                                 cvdcrhd4 = c(7, 9), \n",
    "                                 hlthcvr1 = c(77, 99), \n",
    "                                 chckidny = c(7, 9), \n",
    "                                 useequip = c(7, 9),\n",
    "                                 totinda = 9, \n",
    "                                 addepev2 = c(7, 9),\n",
    "                                 renthom1 = c(7, 9),\n",
    "                                 exerany2 = c(7, 9),\n",
    "                                 blind = c(7, 9),\n",
    "                                 decide = c(7, 9),\n",
    "                                 hlthpln1 = c(7, 9), \n",
    "                                 genhlth = c(7, 9), \n",
    "                                 ageg5yr = 14,\n",
    "                                 smoker3=9,\n",
    "                                 asthma3 = c(7, 9)))%>%\n",
    "  mutate(children = replace(children, children == 88, 0)) %>%\n",
    "  mutate(drvisits = replace(drvisits, drvisits == 88, 0)) %>%\n",
    "  mutate(menthlth = replace(menthlth, menthlth == 88, 0)) %>%\n",
    "  mutate(checkup1 = replace(checkup1, checkup1 == 88, 0)) %>%\n",
    "  mutate(marital = marital_23) %>%\n",
    "  mutate(diabete3 = diabete3_x) %>%\n",
    "  select(-c(marital_23, diabete3_x))\n",
    "```\n",
    "\n",
    "    ## mutate: changed 3,670 values (73%) of 'children' (0 new NA)\n",
    "\n",
    "    ## mutate: changed 351 values (7%) of 'drvisits' (0 new NA)\n",
    "\n",
    "    ## mutate: changed 3,454 values (69%) of 'menthlth' (0 new NA)\n",
    "\n",
    "    ## mutate: no changes\n",
    "\n",
    "    ## mutate: new variable 'marital' (double) with 7 unique values and 1% NA\n",
    "\n",
    "    ## mutate: new variable 'diabete3' (double) with 5 unique values and <1% NA\n",
    "\n",
    "    ## select: dropped 2 variables (diabete3_x, marital_23)\n",
    "\n",
    "## The documentation specifies that some weight values are in kilograms– convert all of them to pounds\n",
    "\n",
    "``` r\n",
    "data3_cleanweight1 <- data3 %>%\n",
    "  mutate(\n",
    "    weight_correct = case_when(\n",
    "      nchar(as.character(weight2))==4 ~ as.numeric(str_sub(weight2, -3)) * 2.20462,\n",
    "      TRUE ~ weight2\n",
    "    )) %>%\n",
    "  select(-weight2)\n",
    "```\n",
    "\n",
    "    ## mutate: new variable 'weight_correct' (double) with 230 unique values and 5% NA\n",
    "\n",
    "    ## select: dropped one variable (weight2)\n",
    "\n",
    "## Check for unique ID’s\n",
    "\n",
    "``` r\n",
    "uniqueidcheck <- data3_cleanweight1 %>% \n",
    "  group_by(personid) %>% \n",
    "  mutate(duplicate_name = n()-1)\n",
    "```\n",
    "\n",
    "    ## group_by: one grouping variable (personid)\n",
    "\n",
    "    ## mutate (grouped): new variable 'duplicate_name' (double) with one unique value and 0% NA\n",
    "\n",
    "``` r\n",
    "# All ID's are unique! \n",
    "```\n",
    "\n",
    "## Checking distributions of all variables\n",
    "\n",
    "``` r\n",
    "skewness(data3_cleanweight1)\n",
    "```\n",
    "\n",
    "    ##       personid       numadult       children       drvisits        genhlth \n",
    "    ##     0.01087417             NA             NA             NA             NA \n",
    "    ##        ageg5yr        bmi5cat       checkup1        income2         educag \n",
    "    ##             NA             NA             NA             NA     0.99310206 \n",
    "    ##       sleptim1       menthlth        smoker3           race         mscode \n",
    "    ##             NA             NA             NA             NA             NA \n",
    "    ##       flushot6        employ1            sex       cvdcrhd4       hlthcvr1 \n",
    "    ##             NA             NA    -0.36261709             NA             NA \n",
    "    ##       chckidny       useequip        totinda       addepev2       renthom1 \n",
    "    ##             NA             NA             NA             NA             NA \n",
    "    ##       exerany2          blind         decide       hlthpln1          state \n",
    "    ##             NA             NA             NA             NA     0.11260066 \n",
    "    ##        asthma3        marital       diabete3 weight_correct \n",
    "    ##             NA             NA             NA             NA\n",
    "\n",
    "## Check missingness of data using vis_dat– sorts columns according to types of data\n",
    "\n",
    "``` r\n",
    "vis_dat(data3_cleanweight1)\n",
    "```\n",
    "\n",
    "    ## Warning: `gather_()` was deprecated in tidyr 1.2.0.\n",
    "    ## ℹ Please use `gather()` instead.\n",
    "    ## ℹ The deprecated feature was likely used in the visdat package.\n",
    "    ##   Please report the issue at <https://github.com/ropensci/visdat/issues>.\n",
    "\n",
    "<img src=\"attachment:vertopal_67aac4bb34854707b7da284d2ad3a3c8/34ec138c20f5f6c3f35d926ad3a0cc73542481c0.png\" width=\"672\" />\n",
    "\n",
    "## Omit variables with most missingness as indicated by visualization above\n",
    "\n",
    "### Given the data we have, we are interested in predicting cases of type 2 diabetes and assume that diabete3 captures type 2. Type 1 diabetes is a genetic condition that often shows up early in life, and type 2 is mainly lifestyle-related and develops over time.\n",
    "\n",
    "``` r\n",
    "data4 <- data3_cleanweight1 %>%\n",
    "  select(-c(numadult, drvisits, mscode, income2, hlthcvr1)) %>%\n",
    "  filter(ageg5yr > 3) %>%\n",
    "# The US Preventative Service Task Force recommends that screenings for diabetes should start at age 35, so we only include individuals 35 or older.  \n",
    "  filter(diabete3 == 1 | diabete3 == 3) %>%\n",
    "#We are not interested in anyone with gestational diabetes or prediabetic individuals because they are not official diabetes diagnoses. Even if we were interested in keeping gestational diabetes or prediabetes as covariates, we could not use them because it is unknown of those respondents have type 2 diagnoses later. \n",
    "  mutate(diabete3 = case_when(diabete3 == 3 ~ 0, \n",
    "         TRUE ~ 1)) %>%\n",
    "  na.omit()\n",
    "```\n",
    "\n",
    "    ## select: dropped 5 variables (numadult, drvisits, income2, mscode, hlthcvr1)\n",
    "\n",
    "    ## filter: removed 793 rows (16%), 4,207 rows remaining\n",
    "\n",
    "    ## filter: removed 104 rows (2%), 4,103 rows remaining\n",
    "\n",
    "    ## mutate: changed 3,493 values (85%) of 'diabete3' (0 new NA)\n",
    "\n",
    "``` r\n",
    "# After this modification, we have 3609 observations\n",
    "```\n",
    "\n",
    "## Check racial breakdown of data and assess if it is representative of nation\n",
    "\n",
    "``` r\n",
    "data4_sample <- data4 %>%\n",
    "  group_by(race) %>%\n",
    "  mutate(Freq=n()) %>%\n",
    "  mutate(perc_total_respondents = Freq/3808*100) %>%\n",
    "  # Compare perc_total_respondents with actual national racial breakdown using https://www.census.gov/content/dam/Census/library/publications/2015/demo/p25-1143.pdf page 9\n",
    "  # There are a disproportionate number of white respondents, which could potentially skew the sample \n",
    "  # We use weights to fix for heteroskedasticity AFTER establishing the training and test models because the representative-ness will change based on the random sample\n",
    "  ungroup()\n",
    "```\n",
    "\n",
    "    ## group_by: one grouping variable (race)\n",
    "\n",
    "    ## mutate (grouped): new variable 'Freq' (integer) with 7 unique values and 0% NA\n",
    "\n",
    "    ## mutate (grouped): new variable 'perc_total_respondents' (double) with 7 unique values and 0% NA\n",
    "\n",
    "    ## ungroup: no grouping variables\n",
    "\n",
    "# The following variables are categorical or ordinal. We need to convert the following objects to factors to represent that.\n",
    "\n",
    "``` r\n",
    "data4_sample$diabete3 <- factor(data4_sample$diabete3)\n",
    "data4_sample$race <- factor(data4_sample$race)\n",
    "data4_sample$sex <- factor(data4_sample$sex)\n",
    "data4_sample$ageg5yr <- factor(data4_sample$ageg5yr)\n",
    "data4_sample$bmi5cat <- factor(data4_sample$bmi5cat)\n",
    "data4_sample$smoker3 <- factor(data4_sample$smoker3)\n",
    "data4_sample$addepev2 <- factor(data4_sample$addepev2)\n",
    "data4_sample$cvdcrhd4 <- factor(data4_sample$cvdcrhd4)\n",
    "data4_sample$chckidny <- factor(data4_sample$chckidny)\n",
    "data4_sample$totinda <- factor(data4_sample$totinda)\n",
    "data4_sample$genhlth <- factor(data4_sample$genhlth)\n",
    "data4_sample$employ1 <- factor(data4_sample$employ1)\n",
    "data4_sample$useequip <- factor(data4_sample$useequip)\n",
    "data4_sample$asthma3 <- factor(data4_sample$asthma3)\n",
    "data4_sample$hlthpln1 <- factor(data4_sample$hlthpln1)\n",
    "data4_sample$decide <- factor(data4_sample$decide)\n",
    "data4_sample$blind <- factor(data4_sample$blind)\n",
    "data4_sample$exerany2 <- factor(data4_sample$exerany2)\n",
    "```\n",
    "\n",
    "# Before we start modeling, let’s check the distribution of diabetes\n",
    "\n",
    "``` r\n",
    "prop.table(table(data4_sample$diabete3))\n",
    "```\n",
    "\n",
    "    ## \n",
    "    ##         0         1 \n",
    "    ## 0.8555882 0.1444118\n",
    "\n",
    "##### Given the result above, I considered over and undersampling the data because of the 86/14 split on no diabetes/diabetes and was worried that the imbalance would skew the model. However, I decided against it for the following reasons:\n",
    "\n",
    "###### According to the National Diabetes Statistics Report (2014), 9.3% of the U.S. population has diabetes, meaning that we are not necessarily aiming for a 50/50 split and our sample is relatively representative of the US. Of the 9.3%, 27.8% are undiagnosed which our model aims to solve for. Because we are interested in accurate prediction and I believe the data is representative, we do not have to correct.\n",
    "\n",
    "###### There is a large risk of overfitting in the over-sampled model\n",
    "\n",
    "###### Under-sampling would reduce the sample and undermine its effectiveness\n",
    "\n",
    "###### The usefulness (AUC value) of the over, under, and non-sampled models would remain the same (or be very close to each other). This is because changing the class ratio only affects the intercept of a standard logistic regression model. It is a monotonic transformation of the log-odds. This also represents a monotonic function of the predicted probability values. Monotonic functions preserve order, and AUC stays the same with order meaning the AUC does not change.\n",
    "\n",
    "###### With our size sample, we have more than 600 observations in our minority class. Given that we can typically fit about 1 parameter per 15 members of the minority class without overfitting, we have enough flexibility in the sample.\n",
    "\n",
    "## Section 2.1: Visualizing potentially relevant variables\n",
    "\n",
    "## Demographic Factors\n",
    "\n",
    "##### BMI- bmi5cat\n",
    "\n",
    "##### Age - ageg5yr\n",
    "\n",
    "##### Gender - sex\n",
    "\n",
    "##### Race - race\n",
    "\n",
    "## Social Factors\n",
    "\n",
    "##### Stress - menthlth\n",
    "\n",
    "##### Depression - addepev2\n",
    "\n",
    "## Lifestyle Factors\n",
    "\n",
    "##### Smoking - smoker3\n",
    "\n",
    "##### Physical exercise - totinda\n",
    "\n",
    "##### Sleep - sleptim1\n",
    "\n",
    "## Medical History\n",
    "\n",
    "##### Diagnosed with coronary heart disease or angina - cvdcrhd4\n",
    "\n",
    "##### Ever told you have kidney disease - chckidny\n",
    "\n",
    "``` r\n",
    "data4_sample$cvdcrhd4 <- as.factor(data4_sample$cvdcrhd4)\n",
    "heartdisease_hist <- ggplot(data4_sample, aes=cvdcrhd4) + geom_histogram()\n",
    "```\n",
    "\n",
    "## It would be nice to include clinical factors such as skin thickness, blood pressure, and glucose levels\n",
    "\n",
    "## But we don’t have those, so we can include chronic heart conditions - cvdcrhd4, chckidny\n",
    "\n",
    "## Can also proxy for some of these using sleep\n",
    "\n",
    "# Section 3: Model Selection:\n",
    "\n",
    "## Use the Boruta algorithm to see what variables are relevant in the data. Based on the earlier visualization, we omit numadult, drvisits, mscode, income2, and hlthcvr1 because they are largely missing from the data and we will not use them as predictors because of that.\n",
    "\n",
    "``` r\n",
    "boruta_data <- data4_sample %>%\n",
    "  select(-c(Freq, perc_total_respondents, personid,weight_correct))\n",
    "```\n",
    "\n",
    "    ## select: dropped 4 variables (personid, weight_correct, Freq, perc_total_respondents)\n",
    "\n",
    "``` r\n",
    "#Omit varialbes that we don't intend on using in our model\n",
    "boruta_train <- Boruta(diabete3~., data = boruta_data)\n",
    "# Confirmed, non-tentative: The following variables are predictive and should be kept.\n",
    "# children, genhlth, ageg5yr,bmi5cat, educag, sleptim1, menthlth, race, employ1, cvdcrhd4, chckidny, useequip, addepev2, exerany2, decide, marital, sex\n",
    "# Tentative. The algorithm was indecisive about if these are predictive. It is up to us to include. \n",
    "# checkup1, smoker3, totinda\n",
    "```\n",
    "\n",
    "## Create correlation plot for selected variables\n",
    "\n",
    "``` r\n",
    "model.matrix(~0+.-Freq-perc_total_respondents-personid-state, data=data4_sample) %>% \n",
    "     cor(use=\"pairwise.complete.obs\") %>% \n",
    "     ggcorrplot(show.diag = F, type=\"lower\", lab=TRUE, lab_size=2)\n",
    "```\n",
    "\n",
    "<img src=\"attachment:vertopal_67aac4bb34854707b7da284d2ad3a3c8/a5bc7ed6c5372cfe7d812f6a95f0fb2aad82bdb8.png\" width=\"672\" />\n",
    "\n",
    "``` r\n",
    "# Given the figure, omit totinda \n",
    "# No physical activity in the past 30 days is 100% correlated with no physical exercise in the past 30 days. Because totinda is a tentative attribute according to the Boruta algorithm, we opt to use exerany. \n",
    "```\n",
    "\n",
    "# Section 3.1: Look into all of the variables specified by Boruta:\n",
    "\n",
    "``` r\n",
    "children_hist <- ggplot(data4_sample, aes(x=children)) + geom_histogram()\n",
    "genhlth_hist <- ggplot(data4_sample, aes(x=genhlth)) + geom_bar() + labs(y=\"Count\", x = \"Gen. Health Category\")\n",
    "ageg5yr_hist <- ggplot(data4_sample, aes(x=ageg5yr)) + geom_bar() + labs(y=\"Count\", x = \"Age Category\")\n",
    "bmi5cat_hist <- ggplot(data4_sample, aes(x=bmi5cat)) + geom_bar() + labs(y=\"Count\", x = \"BMI Category\")\n",
    "checkup_hist <- ggplot(data4_sample, aes(x=checkup1)) + geom_bar()\n",
    "educag_hist <- ggplot(data4_sample, aes(x=educag)) + geom_bar()+\n",
    "  scale_x_discrete(breaks=c(1, 2, 3, 4, 5, 6, 7, 8, 9))\n",
    "sleptim_hist <- ggplot(data4_sample, aes(x=sleptim1)) + geom_histogram(bins=30) + labs(y=\"Count\", x = \"Hours Slept/24 Hours\")\n",
    "menthlth_hist <- ggplot(data4_sample, aes(x=menthlth)) + geom_histogram(bins=45) + labs(y=\"Count\", x = \"# Poor Mental Health Days in the Past Month\")\n",
    "employ1_hist <- ggplot(data4_sample, aes(x=employ1)) + geom_bar()\n",
    "race_hist <- ggplot(data4_sample, aes(x=race)) + geom_bar() + labs(y=\"Count\", x = \"Race\")\n",
    "cvdcrhd4_table <- table(data4_sample$cvdcrhd4)\n",
    "cvdcrhd4_hist <- ggplot(data4_sample) + geom_bar(aes(x=cvdcrhd4)) + labs(y=\"Count\", x = \"Chronic Heart Disease? (Y/N\")\n",
    "chckidny_table <- table(data4_sample$chckidny)\n",
    "chckidny_hist <- ggplot(data4_sample) + geom_bar(aes(x=chckidny)) + labs(y=\"Count\", x = \"Kidney Disease? (Y/N\")\n",
    "useequip_table <- table(data4_sample$useequip)\n",
    "addepev2_table <- table(data4_sample$addepev2)\n",
    "addepev2_hist <- ggplot(data4_sample) + geom_bar(aes(x=addepev2)) + labs(y=\"Count\", x = \"Depressive Disorder? (Y/N)\")\n",
    "exerany_table <- table(data4_sample$exerany2)\n",
    "exerany_hist <- ggplot(data4_sample) + geom_bar(aes(x=exerany2)) + labs(y=\"Count\", x = \"Exercise in the Past Month (Y/N)\")\n",
    "decide_table <- table(data4_sample$decide)\n",
    "marital_hist <- ggplot(data4_sample, aes(x=marital)) + geom_bar() + labs(y=\"Count\", x = \"Marital Status\")\n",
    "sex_table <- table(data4_sample$sex)\n",
    "smoker3_hist <- ggplot(data4_sample, aes(x=smoker3)) + geom_bar() + labs(y=\"Count\", x = \"Smoker Status\")\n",
    "sex_hist <- ggplot(data4_sample) + geom_bar(aes(x=sex)) + labs(y=\"Count\", x = \"Sex\")\n",
    "\n",
    "\n",
    "relevant_vars <- grid.arrange(bmi5cat_hist, ageg5yr_hist, race_hist, sex_hist, menthlth_hist, addepev2_hist,\n",
    "                              sleptim_hist, exerany_hist, smoker3_hist, cvdcrhd4_hist, chckidny_hist, \n",
    "                              ncol=3, nrow =4)\n",
    "```\n",
    "\n",
    "<img src=\"attachment:vertopal_67aac4bb34854707b7da284d2ad3a3c8/d1a0e08cefb66f69db6072b8bff20808940344df.png\" width=\"672\" />\n",
    "\n",
    "``` r\n",
    "ggsave(\"/Users/snerbs/Desktop/GitHub/DigitalCorpsApp/relevant_vars\", \n",
    "       relevant_vars, \n",
    "       device = png,\n",
    "       width=10,\n",
    "       height=10\n",
    ")\n",
    "```\n",
    "\n",
    "# Section 3.2: Split the data into training and test sets before adjusting the samples.\n",
    "\n",
    "## We use the training data to test and validate the model then treat the test dataset as new data to evaluate how effective the model is. We will adjust the racial representative-ness of the sample in the training data. When we split the data into training and test sets, the data is randomly divided, meaning the training and/or test sets may have the same racial split as the lar\n",
    "\n",
    "``` r\n",
    "train <- data4_sample %>% \n",
    "  dplyr::sample_frac(0.75) %>%\n",
    "  group_by(race) %>%\n",
    "  mutate(perc_population = case_when(race == 1 ~  77.5,\n",
    "                                     race == 2 ~ 13.2,\n",
    "                                     race == 3 ~ 1.2, \n",
    "                                     race == 4 ~ 5.4, \n",
    "                                     race == 5 ~ 0.2, \n",
    "                                     race == 7 ~ 2.5, \n",
    "                         TRUE~15.3)) %>%\n",
    "  ## Used https://www.census.gov/content/dam/Census/library/publications/2015/demo/p25-1143.pdf page 9\n",
    "  ## subtracted 2.1 from the hispanic because we have 17.4 percent hispanic and that is not ONLY hispanic\n",
    "  mutate(race_weight = perc_population/perc_total_respondents) %>%\n",
    "  select(-c(perc_population, perc_total_respondents, Freq)) %>%\n",
    "  ungroup()\n",
    "```\n",
    "\n",
    "    ## group_by: one grouping variable (race)\n",
    "\n",
    "    ## mutate (grouped): new variable 'perc_population' (double) with 7 unique values and 0% NA\n",
    "\n",
    "    ## mutate (grouped): new variable 'race_weight' (double) with 7 unique values and 0% NA\n",
    "\n",
    "    ## select: dropped 3 variables (Freq, perc_total_respondents, perc_population)\n",
    "\n",
    "    ## ungroup: no grouping variables\n",
    "\n",
    "``` r\n",
    "prop.table(table(train$diabete3))\n",
    "```\n",
    "\n",
    "    ## \n",
    "    ##         0         1 \n",
    "    ## 0.8564706 0.1435294\n",
    "\n",
    "``` r\n",
    "# Creating test sample-- still need to create a racially representative sample here as well before testing the model we created\n",
    "test  <- dplyr::anti_join(data4_sample, train, by = 'personid') %>%\n",
    "  group_by(race) %>%\n",
    "  mutate(Freq=n()) %>%\n",
    "  mutate(perc_total_respondents = Freq/3808*100) %>%\n",
    "  mutate(perc_population = case_when(race == 1 ~  77.5,\n",
    "                                     race == 2 ~ 13.2,\n",
    "                                     race == 3 ~ 1.2, \n",
    "                                     race == 4 ~ 5.4, \n",
    "                                     race == 5 ~ 0.2, \n",
    "                                     race == 7 ~ 2.5, \n",
    "                         TRUE~15.3)) %>%\n",
    "  # Used https://www.census.gov/content/dam/Census/library/publications/2015/demo/p25-1143.pdf page 9\n",
    "  # subtracted 2.1 from the hispanic because we have 17.4 percent hispanic and that is not ONLY hispanic\n",
    "  mutate(race_weight = perc_population/perc_total_respondents) %>%\n",
    "  select(-c(perc_population, perc_total_respondents, Freq)) %>%\n",
    "  ungroup()\n",
    "```\n",
    "\n",
    "    ## group_by: one grouping variable (race)\n",
    "\n",
    "    ## mutate (grouped): changed 850 values (100%) of 'Freq' (0 new NA)\n",
    "\n",
    "    ## mutate (grouped): changed 850 values (100%) of 'perc_total_respondents' (0 new NA)\n",
    "\n",
    "    ## mutate (grouped): new variable 'perc_population' (double) with 7 unique values and 0% NA\n",
    "\n",
    "    ## mutate (grouped): new variable 'race_weight' (double) with 7 unique values and 0% NA\n",
    "\n",
    "    ## select: dropped 3 variables (Freq, perc_total_respondents, perc_population)\n",
    "\n",
    "    ## ungroup: no grouping variables\n",
    "\n",
    "``` r\n",
    "prop.table(table(test$diabete3))\n",
    "```\n",
    "\n",
    "    ## \n",
    "    ##         0         1 \n",
    "    ## 0.8529412 0.1470588\n",
    "\n",
    "# Section 4: Deploying the logit model\n",
    "\n",
    "## Now that we have the following:\n",
    "\n",
    "### Clean data\n",
    "\n",
    "### Training/test sets,\n",
    "\n",
    "## We can use a logit model to predict if someone will be diagnosed with diabetes.\n",
    "\n",
    "## Run the regression and examine the results\n",
    "\n",
    "``` r\n",
    "mylogit <- glm(diabete3 ~children+genhlth+ageg5yr+bmi5cat+checkup1+educag+sleptim1+menthlth+race+employ1+cvdcrhd4+chckidny+useequip+addepev2+exerany2+decide+marital+sex+smoker3, data = train, family = binomial(link = \"logit\"), weights = race_weight)\n",
    "```\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "``` r\n",
    "anova_logit <- anova(mylogit, test=\"Chisq\")\n",
    "```\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "``` r\n",
    "# Use a chi-squared test because we have a lot of categorical and ordinal variables. The p values we have in the regression output correspond to individual Wald tests, but those p values do not tell us if the entire categorical/ordinal variable) explains the probability of getting diabetes. We have to test the coefficients together, so we perform a deviance goodness of fit test. \n",
    "```\n",
    "\n",
    "## View regression output\n",
    "\n",
    "``` r\n",
    "summary(mylogit)\n",
    "```\n",
    "\n",
    "    ## \n",
    "    ## Call:\n",
    "    ## glm(formula = diabete3 ~ children + genhlth + ageg5yr + bmi5cat + \n",
    "    ##     checkup1 + educag + sleptim1 + menthlth + race + employ1 + \n",
    "    ##     cvdcrhd4 + chckidny + useequip + addepev2 + exerany2 + decide + \n",
    "    ##     marital + sex + smoker3, family = binomial(link = \"logit\"), \n",
    "    ##     data = train, weights = race_weight)\n",
    "    ## \n",
    "    ## Deviance Residuals: \n",
    "    ##     Min       1Q   Median       3Q      Max  \n",
    "    ## -2.9896  -0.5817  -0.3147  -0.1267   5.1178  \n",
    "    ## \n",
    "    ## Coefficients:\n",
    "    ##              Estimate Std. Error z value Pr(>|z|)    \n",
    "    ## (Intercept) -4.413947   1.025538  -4.304 1.68e-05 ***\n",
    "    ## children     0.013981   0.094485   0.148 0.882368    \n",
    "    ## genhlth2     1.341794   0.356822   3.760 0.000170 ***\n",
    "    ## genhlth3     2.095544   0.347606   6.029 1.65e-09 ***\n",
    "    ## genhlth4     2.486107   0.360560   6.895 5.38e-12 ***\n",
    "    ## genhlth5     2.627182   0.406841   6.458 1.06e-10 ***\n",
    "    ## ageg5yr5     0.011885   0.565895   0.021 0.983244    \n",
    "    ## ageg5yr6     0.784119   0.485391   1.615 0.106216    \n",
    "    ## ageg5yr7     1.548675   0.461626   3.355 0.000794 ***\n",
    "    ## ageg5yr8     1.659600   0.462781   3.586 0.000336 ***\n",
    "    ## ageg5yr9     2.198943   0.459947   4.781 1.75e-06 ***\n",
    "    ## ageg5yr10    1.831407   0.471743   3.882 0.000104 ***\n",
    "    ## ageg5yr11    1.903659   0.490833   3.878 0.000105 ***\n",
    "    ## ageg5yr12    2.251144   0.495651   4.542 5.58e-06 ***\n",
    "    ## ageg5yr13    2.081762   0.500363   4.161 3.18e-05 ***\n",
    "    ## bmi5cat2     0.083162   0.650167   0.128 0.898221    \n",
    "    ## bmi5cat3     0.757463   0.641477   1.181 0.237678    \n",
    "    ## bmi5cat4     1.405568   0.640550   2.194 0.028213 *  \n",
    "    ## checkup1    -0.415597   0.097185  -4.276 1.90e-05 ***\n",
    "    ## educag      -0.068063   0.059078  -1.152 0.249292    \n",
    "    ## sleptim1     0.001327   0.037328   0.036 0.971645    \n",
    "    ## menthlth    -0.013722   0.008938  -1.535 0.124741    \n",
    "    ## race2        0.724072   0.164708   4.396 1.10e-05 ***\n",
    "    ## race3        0.835989   0.469367   1.781 0.074896 .  \n",
    "    ## race4       -0.069662   0.358150  -0.195 0.845781    \n",
    "    ## race5        1.794536   1.184515   1.515 0.129773    \n",
    "    ## race7        0.367320   0.371494   0.989 0.322777    \n",
    "    ## race8        0.811533   0.165652   4.899 9.63e-07 ***\n",
    "    ## employ12    -0.199348   0.279758  -0.713 0.476111    \n",
    "    ## employ13     0.650115   0.329446   1.973 0.048455 *  \n",
    "    ## employ14     0.030799   0.541256   0.057 0.954623    \n",
    "    ## employ15     0.048120   0.303040   0.159 0.873834    \n",
    "    ## employ16     2.374579   0.883488   2.688 0.007194 ** \n",
    "    ## employ17     0.285359   0.183829   1.552 0.120589    \n",
    "    ## employ18     0.292031   0.227059   1.286 0.198392    \n",
    "    ## cvdcrhd42   -0.635831   0.169738  -3.746 0.000180 ***\n",
    "    ## chckidny2   -0.782970   0.233609  -3.352 0.000803 ***\n",
    "    ## useequip2   -0.307082   0.153526  -2.000 0.045479 *  \n",
    "    ## addepev22   -0.529555   0.152928  -3.463 0.000535 ***\n",
    "    ## exerany22   -0.143629   0.129437  -1.110 0.267150    \n",
    "    ## decide2      0.293288   0.192533   1.523 0.127682    \n",
    "    ## marital      0.067892   0.042155   1.611 0.107286    \n",
    "    ## sex2        -0.339673   0.121407  -2.798 0.005145 ** \n",
    "    ## smoker32     0.151616   0.331875   0.457 0.647782    \n",
    "    ## smoker33     0.408584   0.230108   1.776 0.075796 .  \n",
    "    ## smoker34     0.562062   0.228545   2.459 0.013921 *  \n",
    "    ## ---\n",
    "    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "    ## \n",
    "    ## (Dispersion parameter for binomial family taken to be 1)\n",
    "    ## \n",
    "    ##     Null deviance: 2821.9  on 2549  degrees of freedom\n",
    "    ## Residual deviance: 2106.8  on 2504  degrees of freedom\n",
    "    ## AIC: 2137\n",
    "    ## \n",
    "    ## Number of Fisher Scoring iterations: 6\n",
    "\n",
    "``` r\n",
    "anova_logit\n",
    "```\n",
    "\n",
    "    ## Analysis of Deviance Table\n",
    "    ## \n",
    "    ## Model: binomial, link: logit\n",
    "    ## \n",
    "    ## Response: diabete3\n",
    "    ## \n",
    "    ## Terms added sequentially (first to last)\n",
    "    ## \n",
    "    ## \n",
    "    ##          Df Deviance Resid. Df Resid. Dev  Pr(>Chi)    \n",
    "    ## NULL                      2549     2821.9              \n",
    "    ## children  1    59.83      2548     2762.1 1.033e-14 ***\n",
    "    ## genhlth   4   326.00      2544     2436.1 < 2.2e-16 ***\n",
    "    ## ageg5yr   9    80.99      2535     2355.1 1.029e-13 ***\n",
    "    ## bmi5cat   3    93.15      2532     2261.9 < 2.2e-16 ***\n",
    "    ## checkup1  1    28.21      2531     2233.7 1.087e-07 ***\n",
    "    ## educag    1     1.41      2530     2232.3 0.2343991    \n",
    "    ## sleptim1  1     0.03      2529     2232.3 0.8597398    \n",
    "    ## menthlth  1     1.28      2528     2231.0 0.2584787    \n",
    "    ## race      6    38.78      2522     2192.2 7.913e-07 ***\n",
    "    ## employ1   7    19.10      2515     2173.1 0.0078847 ** \n",
    "    ## cvdcrhd4  1    19.66      2514     2153.5 9.272e-06 ***\n",
    "    ## chckidny  1    13.98      2513     2139.5 0.0001845 ***\n",
    "    ## useequip  1     4.63      2512     2134.9 0.0314828 *  \n",
    "    ## addepev2  1     8.31      2511     2126.6 0.0039484 ** \n",
    "    ## exerany2  1     1.85      2510     2124.7 0.1734463    \n",
    "    ## decide    1     2.38      2509     2122.3 0.1228065    \n",
    "    ## marital   1     1.21      2508     2121.1 0.2708230    \n",
    "    ## sex       1     6.55      2507     2114.6 0.0104763 *  \n",
    "    ## smoker3   3     7.76      2504     2106.8 0.0513424 .  \n",
    "    ## ---\n",
    "    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "\n",
    "``` r\n",
    "# How to interpret this test: rejecting the null means the reduction in deviance is larger than one would expect if a variable did not explain anything about the outcome\n",
    "```\n",
    "\n",
    "## Section 4.1: Make predictions using test data\n",
    "\n",
    "``` r\n",
    "probabilities <- mylogit %>% predict(test, type = \"response\")\n",
    "# The result is continuous values of probabilities of diabetes occurrence, but we are interested in predicting if someone will have diabetes or not. If anyone has a probability above 50%, we assume that they will be diagnosed with diabetes.\n",
    "predicted_classes <- ifelse(probabilities > 0.5, 1, 0)\n",
    "```\n",
    "\n",
    "## Section 4.2: Evaluate the model by creating a confusion matrix\n",
    "\n",
    "``` r\n",
    "# Take the predictions and append as a column to the test dataframe to create a confusion matrix\n",
    "# Do do that, we must first converting predicted classes to a dataframe\n",
    "predicted_classes_logit <- as.data.frame(predicted_classes)\n",
    "test_predicted_logit <- cbind(predicted_classes_logit, test) \n",
    "logitconfusionmatrix <-confusionMatrix(data=as.factor(test_predicted_logit$predicted_classes), reference=as.factor(test_predicted_logit$diabete3))\n",
    "```\n",
    "\n",
    "``` r\n",
    "logitconfusionmatrix\n",
    "```\n",
    "\n",
    "    ## Confusion Matrix and Statistics\n",
    "    ## \n",
    "    ##           Reference\n",
    "    ## Prediction   0   1\n",
    "    ##          0 697 104\n",
    "    ##          1  28  21\n",
    "    ##                                           \n",
    "    ##                Accuracy : 0.8447          \n",
    "    ##                  95% CI : (0.8186, 0.8684)\n",
    "    ##     No Information Rate : 0.8529          \n",
    "    ##     P-Value [Acc > NIR] : 0.7678          \n",
    "    ##                                           \n",
    "    ##                   Kappa : 0.1729          \n",
    "    ##                                           \n",
    "    ##  Mcnemar's Test P-Value : 6.669e-11       \n",
    "    ##                                           \n",
    "    ##             Sensitivity : 0.9614          \n",
    "    ##             Specificity : 0.1680          \n",
    "    ##          Pos Pred Value : 0.8702          \n",
    "    ##          Neg Pred Value : 0.4286          \n",
    "    ##              Prevalence : 0.8529          \n",
    "    ##          Detection Rate : 0.8200          \n",
    "    ##    Detection Prevalence : 0.9424          \n",
    "    ##       Balanced Accuracy : 0.5647          \n",
    "    ##                                           \n",
    "    ##        'Positive' Class : 0               \n",
    "    ## \n",
    "\n",
    "## Section 4.3: Create ROC Curve to calculate the performance of the classification model\n",
    "\n",
    "``` r\n",
    "roc_object <- roc(test$diabete3, probabilities)\n",
    "```\n",
    "\n",
    "    ## Setting levels: control = 0, case = 1\n",
    "\n",
    "    ## Setting direction: controls < cases\n",
    "\n",
    "``` r\n",
    "# Calculate area under curve, the closer this is to 1 the more useful the model is\n",
    "auc_logit <- auc(roc_object) \n",
    "auc_logit\n",
    "```\n",
    "\n",
    "    ## Area under the curve: 0.7789\n",
    "\n",
    "# Section 5: Decision trees\n",
    "\n",
    "``` r\n",
    "decisiontree <- rpart(diabete3 ~children+genhlth+ageg5yr+bmi5cat+checkup1+educag+sleptim1+menthlth+race+employ1+cvdcrhd4+chckidny+useequip+addepev2+exerany2+decide+marital+sex+smoker3, data = train, method='class')\n",
    "rpart.plot(decisiontree)\n",
    "```\n",
    "\n",
    "<img src=\"attachment:vertopal_67aac4bb34854707b7da284d2ad3a3c8/4989817fca189f61fa8064dc58127f911c5e272a.png\" width=\"672\" />\n",
    "\n",
    "## Section 5.1: Make predictions using test data\n",
    "\n",
    "``` r\n",
    "predict_model<-predict(decisiontree, test, type='class')\n",
    "```\n",
    "\n",
    "## Section 5.2: Evaluate the model by creating a confusion matrix\n",
    "\n",
    "``` r\n",
    "predicted_classes_decisiontree <- as.data.frame(predict_model)\n",
    "test_predicted_decisiontree <- cbind(predicted_classes_decisiontree, test) \n",
    "\n",
    "decisiontree_confusionmatrix<-confusionMatrix(data=test_predicted_decisiontree$predict_model, reference=test_predicted_decisiontree$diabete3)\n",
    "```\n",
    "\n",
    "``` r\n",
    "decisiontree_confusionmatrix\n",
    "```\n",
    "\n",
    "    ## Confusion Matrix and Statistics\n",
    "    ## \n",
    "    ##           Reference\n",
    "    ## Prediction   0   1\n",
    "    ##          0 725 125\n",
    "    ##          1   0   0\n",
    "    ##                                           \n",
    "    ##                Accuracy : 0.8529          \n",
    "    ##                  95% CI : (0.8273, 0.8761)\n",
    "    ##     No Information Rate : 0.8529          \n",
    "    ##     P-Value [Acc > NIR] : 0.5238          \n",
    "    ##                                           \n",
    "    ##                   Kappa : 0               \n",
    "    ##                                           \n",
    "    ##  Mcnemar's Test P-Value : <2e-16          \n",
    "    ##                                           \n",
    "    ##             Sensitivity : 1.0000          \n",
    "    ##             Specificity : 0.0000          \n",
    "    ##          Pos Pred Value : 0.8529          \n",
    "    ##          Neg Pred Value :    NaN          \n",
    "    ##              Prevalence : 0.8529          \n",
    "    ##          Detection Rate : 0.8529          \n",
    "    ##    Detection Prevalence : 1.0000          \n",
    "    ##       Balanced Accuracy : 0.5000          \n",
    "    ##                                           \n",
    "    ##        'Positive' Class : 0               \n",
    "    ## \n",
    "\n",
    "## Section 5.3: Create ROC Curve to calculate the performance of the classification model\n",
    "\n",
    "``` r\n",
    "predict_model <- as.numeric(predict_model)\n",
    "roc_object_decisiontree <- roc(test$diabete3, predict_model)\n",
    "```\n",
    "\n",
    "    ## Setting levels: control = 0, case = 1\n",
    "\n",
    "    ## Setting direction: controls < cases\n",
    "\n",
    "``` r\n",
    "# Calculate area under curve, the closer this is to 1 the more useful the model is\n",
    "auc_decisiontree <- auc(roc_object_decisiontree) \n",
    "auc_decisiontree\n",
    "```\n",
    "\n",
    "    ## Area under the curve: 0.5\n",
    "\n",
    "# Section 6: Random Forests\n",
    "\n",
    "``` r\n",
    "rf <- randomForest(diabete3 ~children+genhlth+ageg5yr+bmi5cat+checkup1+educag+sleptim1+menthlth+race+employ1+cvdcrhd4+chckidny+useequip+addepev2+exerany2+decide+marital+sex+smoker3, data=train, proximity=TRUE, ntree=500) \n",
    "plot(rf)\n",
    "```\n",
    "\n",
    "<img src=\"attachment:vertopal_67aac4bb34854707b7da284d2ad3a3c8/ed646898a25eabb8ba789f5e93abdb8b0f573c3c.png\" width=\"672\" />\n",
    "\n",
    "## Section 6.1: Make predictions using test data\n",
    "\n",
    "``` r\n",
    "pred_randomforest_test <- predict(rf, newdata = test, type= \"class\")\n",
    "```\n",
    "\n",
    "## Section 6.2: Evaluate the model by creating a confusion matrix\n",
    "\n",
    "``` r\n",
    "test_predicted_randomforest <- cbind(pred_randomforest_test, test) \n",
    "\n",
    "confusionmatrixRandomForest <- confusionMatrix(data=as.factor(test_predicted_randomforest$pred_randomforest_test), \n",
    "                                               reference=as.factor(test_predicted_randomforest$diabete3))\n",
    "```\n",
    "\n",
    "``` r\n",
    "confusionmatrixRandomForest\n",
    "```\n",
    "\n",
    "    ## Confusion Matrix and Statistics\n",
    "    ## \n",
    "    ##           Reference\n",
    "    ## Prediction   0   1\n",
    "    ##          0 709 108\n",
    "    ##          1  16  17\n",
    "    ##                                           \n",
    "    ##                Accuracy : 0.8541          \n",
    "    ##                  95% CI : (0.8286, 0.8772)\n",
    "    ##     No Information Rate : 0.8529          \n",
    "    ##     P-Value [Acc > NIR] : 0.4852          \n",
    "    ##                                           \n",
    "    ##                   Kappa : 0.1638          \n",
    "    ##                                           \n",
    "    ##  Mcnemar's Test P-Value : 3.032e-16       \n",
    "    ##                                           \n",
    "    ##             Sensitivity : 0.9779          \n",
    "    ##             Specificity : 0.1360          \n",
    "    ##          Pos Pred Value : 0.8678          \n",
    "    ##          Neg Pred Value : 0.5152          \n",
    "    ##              Prevalence : 0.8529          \n",
    "    ##          Detection Rate : 0.8341          \n",
    "    ##    Detection Prevalence : 0.9612          \n",
    "    ##       Balanced Accuracy : 0.5570          \n",
    "    ##                                           \n",
    "    ##        'Positive' Class : 0               \n",
    "    ## \n",
    "\n",
    "## Section 6.3: Create ROC Curve to calculate the performance of the classification model\n",
    "\n",
    "``` r\n",
    "pred_randomforest_test <-  as.numeric(pred_randomforest_test)\n",
    "# create roc curve\n",
    "roc_object_randomforests <- roc(test$diabete3, pred_randomforest_test)\n",
    "```\n",
    "\n",
    "    ## Setting levels: control = 0, case = 1\n",
    "\n",
    "    ## Setting direction: controls < cases\n",
    "\n",
    "``` r\n",
    "# calculate area under curve\n",
    "auc_randomforests <- auc(roc_object_randomforests)\n",
    "auc_randomforests\n",
    "```\n",
    "\n",
    "    ## Area under the curve: 0.557"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
