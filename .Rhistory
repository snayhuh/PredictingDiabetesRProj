probabilities <- mylogit %>% predict(test, type = "response")
# The result is continuous values of probabilities of diabetes occurrence, but we are interested in predicting if someone will have diabetes or not. If anyone has a probability above 50%, we assume that they will be diagnosed with diabetes.
predicted_classes <- ifelse(probabilities > 0.5, 1, 0)
# Take the predictions and append as a column to the test dataframe to create a confusion matrix
# Do do that, we must first converting predicted classes to a dataframe
predicted_classes_logit <- as.data.frame(predicted_classes)
test_predicted_logit <- cbind(predicted_classes_logit, test)
logitconfusionmatrix <-confusionMatrix(data=as.factor(test_predicted_logit$predicted_classes), reference=as.factor(test_predicted_logit$diabete3))
logitconfusionmatrix
# create roc curve
roc_logit <- roc(test_predicted_logit$diabete3, test_predicted_logit$predicted_classes)
# calculate area under curve
auc_logit <- auc(roc_logit)
auc_logit
decisiontree <- rpart(diabete3 ~children+genhlth+ageg5yr+bmi5cat+checkup1+educag+sleptim1+menthlth+race+employ1+cvdcrhd4+chckidny+useequip+addepev2+exerany2+decide+marital+sex+smoker3, data = train, method='class')
rpart.plot(decisiontree)
predict_model<-predict(decisiontree, test, type='class')
predicted_classes_decisiontree <- as.data.frame(predict_model)
test_predicted_decisiontree <- cbind(predicted_classes_decisiontree, test)
decisiontree_confusionmatrix<-confusionMatrix(data=test_predicted_decisiontree$predict_model, reference=test_predicted_decisiontree$diabete3)
decisiontree_confusionmatrix<-confusionMatrix(data=test_predicted_decisiontree$predict_model, reference=test_predicted_decisiontree$diabete3)
decisiontree_confusionmatrix
predict_model <- as.numeric(predict_model)
roc_object_decisiontree <- roc(test$diabete3, predict_model)
# Calculate area under curve, the closer this is to 1 the more useful the model is
auc_decisiontree <- auc(roc_object_decisiontree)
auc_decisiontree
rf <- randomForest(diabete3 ~children+genhlth+ageg5yr+bmi5cat+checkup1+educag+sleptim1+menthlth+race+employ1+cvdcrhd4+chckidny+useequip+addepev2+exerany2+decide+marital+sex+smoker3, data=train, proximity=TRUE, ntree=500)
plot(rf)
pred_randomforest_test <- predict(rf, newdata = test, type= "class")
test_predicted_randomforest <- cbind(pred_randomforest_test, test)
confusionmatrixRandomForest <- confusionMatrix(data=as.factor(test_predicted_randomforest$pred_randomforest_test),
reference=as.factor(test_predicted_randomforest$diabete3))
confusionmatrixRandomForest <- confusionMatrix(data=as.factor(test_predicted_randomforest$pred_randomforest_test),
reference=as.factor(test_predicted_randomforest$diabete3))
```{r}
confusionmatrixRandomForest
set.seed(324)
knitr::opts_chunk$set(echo = TRUE)
set.seed(324)
### Importing libraries
library(dplyr, warn.conflicts = FALSE)
library(tidyr)
library(tidyverse)
library(tidylog, warn.conflicts = FALSE)
library(visdat)
library(naniar)
library(cdlTools)
library(pROC)
library(caret)
library(e1071)
library(Boruta)
library(Rcpp)
library(randomForest)
library(ROSE)
library(ggcorrplot)
library(party)
library(gridExtra)
library(rpart)
library(rpart.plot)
library(moments)
library(DescTools)
numeric <- read_csv("Data/data_numeric.csv", show_col_types = T)
spec(numeric)
categorical <- read_csv("Data/data_categorical.csv", show_col_types = T)
spec(categorical)
ordinal <- read_csv("Data/data_ordinal.csv", show_col_types = T)
spec(ordinal)
num_ord <- left_join(numeric, ordinal, "PERSONID")
num_ord_cat <- left_join(num_ord, categorical, "PERSONID")
spec(num_ord_cat)
data1 <- num_ord_cat %>%
select(starts_with("DIABET") | starts_with("MARITAL")) %>%
mutate(DIABET3_diff = ifelse(DIABETE3.x == DIABETE3.y &
DIABETE3.x == `DIABETE3...2` &
DIABETE3.x == `DIABETE3...20`, 0, 1)) %>%
## There are 10 NA values in the marital difference variable-- want to see if they are missing for the same observations
mutate(MARITAL_DIFF = ifelse((`MARITAL...8` == `MARITAL...23`) |
(is.na(`MARITAL...8`) & is.na(`MARITAL...23`)), 0 ,1))
data2 <- num_ord_cat %>%
select(-c(DIABETE3.y, `DIABETE3...2`, `DIABETE3...20`, `MARITAL...8`)) %>%
janitor::clean_names()
data3 <- data2 %>%
replace_with_na(replace = list(weight2 = c(9999, 7777),
children = 99,
drvisits = c(77, 99),
income2 = c(77, 99),
checkup1 = c(7, 9),
sleptim1 = c(77, 99),
menthlth = c(77, 99),
diabete3_x = c(7, 9),
race = c(9),
flushot6 = c(7, 9),
employ1 = 9,
marital_23 = 9,
cvdcrhd4 = c(7, 9),
hlthcvr1 = c(77, 99),
chckidny = c(7, 9),
useequip = c(7, 9),
totinda = 9,
addepev2 = c(7, 9),
renthom1 = c(7, 9),
exerany2 = c(7, 9),
blind = c(7, 9),
decide = c(7, 9),
hlthpln1 = c(7, 9),
genhlth = c(7, 9),
ageg5yr = 14,
smoker3=9,
asthma3 = c(7, 9)))%>%
mutate(children = replace(children, children == 88, 0)) %>%
mutate(drvisits = replace(drvisits, drvisits == 88, 0)) %>%
mutate(menthlth = replace(menthlth, menthlth == 88, 0)) %>%
mutate(checkup1 = replace(checkup1, checkup1 == 88, 0)) %>%
mutate(marital = marital_23) %>%
mutate(diabete3 = diabete3_x) %>%
select(-c(marital_23, diabete3_x))
data3_cleanweight1 <- data3 %>%
mutate(
weight_correct = case_when(
nchar(as.character(weight2))==4 ~ as.numeric(str_sub(weight2, -3)) * 2.20462,
TRUE ~ weight2
)) %>%
select(-weight2)
uniqueidcheck <- data3_cleanweight1 %>%
group_by(personid) %>%
mutate(duplicate_name = n()-1)
# All ID's are unique!
skewness(data3_cleanweight1, na.rm = T)
vis_dat(data3_cleanweight1)
data4 <- data3_cleanweight1 %>%
select(-c(numadult, drvisits, mscode, income2, hlthcvr1)) %>%
filter(ageg5yr > 3) %>%
# The US Preventative Service Task Force recommends that screenings for diabetes should start at age 35, so we only include individuals 35 or older.
filter(diabete3 == 1 | diabete3 == 3) %>%
#We are not interested in anyone with gestational diabetes or prediabetic individuals because they are not official diabetes diagnoses. Even if we were interested in keeping gestational diabetes or prediabetes as covariates, we could not use them because it is unknown of those respondents have type 2 diagnoses later.
mutate(diabete3 = case_when(diabete3 == 3 ~ 0,
TRUE ~ 1)) %>%
na.omit()
# After this modification, we have 3417 observations
data4_sample <- data4 %>%
group_by(race) %>%
mutate(Freq=n()) %>%
mutate(perc_total_respondents = Freq/3417*100) %>%
ungroup()
data4_sample$diabete3 <- factor(data4_sample$diabete3)
data4_sample$race <- factor(data4_sample$race)
data4_sample$sex <- factor(data4_sample$sex)
data4_sample$ageg5yr <- factor(data4_sample$ageg5yr)
data4_sample$bmi5cat <- factor(data4_sample$bmi5cat)
data4_sample$smoker3 <- factor(data4_sample$smoker3)
data4_sample$addepev2 <- factor(data4_sample$addepev2)
data4_sample$cvdcrhd4 <- factor(data4_sample$cvdcrhd4)
data4_sample$chckidny <- factor(data4_sample$chckidny)
data4_sample$totinda <- factor(data4_sample$totinda)
data4_sample$genhlth <- factor(data4_sample$genhlth)
data4_sample$employ1 <- factor(data4_sample$employ1)
data4_sample$useequip <- factor(data4_sample$useequip)
data4_sample$asthma3 <- factor(data4_sample$asthma3)
data4_sample$hlthpln1 <- factor(data4_sample$hlthpln1)
data4_sample$decide <- factor(data4_sample$decide)
data4_sample$blind <- factor(data4_sample$blind)
data4_sample$exerany2 <- factor(data4_sample$exerany2)
prop.table(table(data4_sample$diabete3))
data4_sample$cvdcrhd4 <- as.factor(data4_sample$cvdcrhd4)
heartdisease_hist <- ggplot(data4_sample) + geom_histogram(aes(x=cvdcrhd4), stat='count')
boruta_data <- data4_sample %>%
select(-c(Freq, perc_total_respondents, personid,weight_correct))
#Omit varialbes that we don't intend on using in our model
#boruta_train <- Boruta(diabete3~., data = boruta_data)
# Confirmed, non-tentative: The following variables are predictive and should be kept.
# children, genhlth, ageg5yr,bmi5cat, educag, sleptim1, menthlth, race, employ1, cvdcrhd4, chckidny, useequip, addepev2, exerany2, decide, marital, sex
# Tentative. The algorithm was indecisive about if these are predictive. It is up to us to include.
# checkup1, smoker3, totinda
model.matrix(~0+.-Freq-perc_total_respondents-personid-state, data=data4_sample) %>%
cor(use="pairwise.complete.obs") %>%
ggcorrplot(show.diag = F, type="lower", lab=TRUE, lab_size=2)
# Given the figure, omit totinda
# No physical activity in the past 30 days is 100% correlated with no physical exercise in the past 30 days. Because totinda is a tentative attribute according to the Boruta algorithm, we opt to use exerany.
children_hist <- ggplot(data4_sample, aes(x=children)) + geom_histogram()
genhlth_hist <- ggplot(data4_sample, aes(x=genhlth)) + geom_bar() + labs(y="Count", x = "Gen. Health Category")
ageg5yr_hist <- ggplot(data4_sample, aes(x=ageg5yr)) + geom_bar() + labs(y="Count", x = "Age Category")
bmi5cat_hist <- ggplot(data4_sample, aes(x=bmi5cat)) + geom_bar() + labs(y="Count", x = "BMI Category")
checkup_hist <- ggplot(data4_sample, aes(x=checkup1)) + geom_bar()
educag_hist <- ggplot(data4_sample, aes(x=educag)) + geom_bar()+
scale_x_discrete(breaks=c(1, 2, 3, 4, 5, 6, 7, 8, 9))
sleptim_hist <- ggplot(data4_sample, aes(x=sleptim1)) + geom_histogram(bins=30) + labs(y="Count", x = "Hours Slept/24 Hours")
menthlth_hist <- ggplot(data4_sample, aes(x=menthlth)) + geom_histogram(bins=45) + labs(y="Count", x = "# Poor Mental Health Days in the Past Month")
employ1_hist <- ggplot(data4_sample, aes(x=employ1)) + geom_bar()
race_hist <- ggplot(data4_sample, aes(x=race)) + geom_bar() + labs(y="Count", x = "Race")
cvdcrhd4_table <- table(data4_sample$cvdcrhd4)
cvdcrhd4_hist <- ggplot(data4_sample) + geom_bar(aes(x=cvdcrhd4)) + labs(y="Count", x = "Chronic Heart Disease? (Y/N")
chckidny_table <- table(data4_sample$chckidny)
chckidny_hist <- ggplot(data4_sample) + geom_bar(aes(x=chckidny)) + labs(y="Count", x = "Kidney Disease? (Y/N")
useequip_table <- table(data4_sample$useequip)
addepev2_table <- table(data4_sample$addepev2)
addepev2_hist <- ggplot(data4_sample) + geom_bar(aes(x=addepev2)) + labs(y="Count", x = "Depressive Disorder? (Y/N)")
exerany_table <- table(data4_sample$exerany2)
exerany_hist <- ggplot(data4_sample) + geom_bar(aes(x=exerany2)) + labs(y="Count", x = "Exercise in the Past Month (Y/N)")
decide_table <- table(data4_sample$decide)
marital_hist <- ggplot(data4_sample, aes(x=marital)) + geom_bar() + labs(y="Count", x = "Marital Status")
sex_table <- table(data4_sample$sex)
smoker3_hist <- ggplot(data4_sample, aes(x=smoker3)) + geom_bar() + labs(y="Count", x = "Smoker Status")
sex_hist <- ggplot(data4_sample) + geom_bar(aes(x=sex)) + labs(y="Count", x = "Sex")
sd(data4_sample$menthlth)
mean(data4_sample$menthlth)
relevant_vars <- grid.arrange(bmi5cat_hist, ageg5yr_hist, race_hist, sex_hist, menthlth_hist, addepev2_hist,
sleptim_hist, exerany_hist, smoker3_hist, cvdcrhd4_hist, chckidny_hist,
ncol=4, nrow =3)
ggsave("/Users/snerbs/Desktop/GitHub/DigitalCorpsApp/relevant_vars",
relevant_vars,
device = png,
width=10,
height=10
)
train <- data4_sample %>%
dplyr::sample_frac(0.75)
prop.table(table(train$diabete3))
# Creating test sample-- still need to create a racially representative sample here as well before testing the model we created
test  <- dplyr::anti_join(data4_sample, train, by = 'personid')
prop.table(table(test$diabete3))
mylogit <- glm(diabete3 ~children+genhlth+ageg5yr+bmi5cat+checkup1+educag+sleptim1+menthlth+race+employ1+cvdcrhd4+chckidny+useequip+addepev2+exerany2+decide+marital+sex+smoker3, data = train, family = binomial(link = "logit"))
anova_logit <- anova(mylogit, test="Chisq")
# Use a chi-squared test because we have a lot of categorical and ordinal variables. The p values we have in the regression output correspond to individual Wald tests, but those p values do not tell us if the entire categorical/ordinal variable) explains the probability of getting diabetes. We have to test the coefficients together, so we perform a deviance goodness of fit test.
summary(mylogit)
anova_logit
# How to interpret this test: rejecting the null means the reduction in deviance is larger than one would expect if a variable did not explain anything about the outcome
probabilities <- mylogit %>% predict(test, type = "response")
# The result is continuous values of probabilities of diabetes occurrence, but we are interested in predicting if someone will have diabetes or not. If anyone has a probability above 50%, we assume that they will be diagnosed with diabetes.
predicted_classes <- ifelse(probabilities > 0.5, 1, 0)
# Take the predictions and append as a column to the test dataframe to create a confusion matrix
# Do do that, we must first converting predicted classes to a dataframe
predicted_classes_logit <- as.data.frame(predicted_classes)
test_predicted_logit <- cbind(predicted_classes_logit, test)
logitconfusionmatrix <-confusionMatrix(data=as.factor(test_predicted_logit$predicted_classes), reference=as.factor(test_predicted_logit$diabete3))
logitconfusionmatrix
BrierScore(mylogit)
# create roc curve
roc_logit <- roc(test_predicted_logit$diabete3, test_predicted_logit$predicted_classes)
# calculate area under curve
auc_logit <- auc(roc_logit)
auc_logit
decisiontree <- rpart(diabete3 ~children+genhlth+ageg5yr+bmi5cat+checkup1+educag+sleptim1+menthlth+race+employ1+cvdcrhd4+chckidny+useequip+addepev2+exerany2+decide+marital+sex+smoker3, data = train, method='class')
rpart.plot(decisiontree)
rpart.plot(decisiontree)
decisiontree <- rpart(diabete3 ~children+genhlth+ageg5yr+bmi5cat+checkup1+educag+sleptim1+menthlth+race+employ1+cvdcrhd4+chckidny+useequip+addepev2+exerany2+decide+marital+sex+smoker3, data = train, method='class')
rpart.plot(decisiontree)
knitr::opts_chunk$set(echo = TRUE)
set.seed(32)
### Importing libraries
library(dplyr, warn.conflicts = FALSE)
library(tidyr)
library(tidyverse)
library(tidylog, warn.conflicts = FALSE)
library(visdat)
library(naniar)
library(cdlTools)
library(pROC)
library(caret)
library(e1071)
library(Boruta)
library(Rcpp)
library(randomForest)
library(ROSE)
library(ggcorrplot)
library(party)
library(gridExtra)
library(rpart)
library(rpart.plot)
library(moments)
library(DescTools)
numeric <- read_csv("Data/data_numeric.csv", show_col_types = T)
spec(numeric)
categorical <- read_csv("Data/data_categorical.csv", show_col_types = T)
spec(categorical)
ordinal <- read_csv("Data/data_ordinal.csv", show_col_types = T)
spec(ordinal)
num_ord <- left_join(numeric, ordinal, "PERSONID")
num_ord_cat <- left_join(num_ord, categorical, "PERSONID")
spec(num_ord_cat)
data1 <- num_ord_cat %>%
select(starts_with("DIABET") | starts_with("MARITAL")) %>%
mutate(DIABET3_diff = ifelse(DIABETE3.x == DIABETE3.y &
DIABETE3.x == `DIABETE3...2` &
DIABETE3.x == `DIABETE3...20`, 0, 1)) %>%
## There are 10 NA values in the marital difference variable-- want to see if they are missing for the same observations
mutate(MARITAL_DIFF = ifelse((`MARITAL...8` == `MARITAL...23`) |
(is.na(`MARITAL...8`) & is.na(`MARITAL...23`)), 0 ,1))
data2 <- num_ord_cat %>%
select(-c(DIABETE3.y, `DIABETE3...2`, `DIABETE3...20`, `MARITAL...8`)) %>%
janitor::clean_names()
data3 <- data2 %>%
replace_with_na(replace = list(weight2 = c(9999, 7777),
children = 99,
drvisits = c(77, 99),
income2 = c(77, 99),
checkup1 = c(7, 9),
sleptim1 = c(77, 99),
menthlth = c(77, 99),
diabete3_x = c(7, 9),
race = c(9),
flushot6 = c(7, 9),
employ1 = 9,
marital_23 = 9,
cvdcrhd4 = c(7, 9),
hlthcvr1 = c(77, 99),
chckidny = c(7, 9),
useequip = c(7, 9),
totinda = 9,
addepev2 = c(7, 9),
renthom1 = c(7, 9),
exerany2 = c(7, 9),
blind = c(7, 9),
decide = c(7, 9),
hlthpln1 = c(7, 9),
genhlth = c(7, 9),
ageg5yr = 14,
smoker3=9,
asthma3 = c(7, 9)))%>%
mutate(children = replace(children, children == 88, 0)) %>%
mutate(drvisits = replace(drvisits, drvisits == 88, 0)) %>%
mutate(menthlth = replace(menthlth, menthlth == 88, 0)) %>%
mutate(checkup1 = replace(checkup1, checkup1 == 88, 0)) %>%
mutate(marital = marital_23) %>%
mutate(diabete3 = diabete3_x) %>%
select(-c(marital_23, diabete3_x))
data3_cleanweight1 <- data3 %>%
mutate(
weight_correct = case_when(
nchar(as.character(weight2))==4 ~ as.numeric(str_sub(weight2, -3)) * 2.20462,
TRUE ~ weight2
)) %>%
select(-weight2)
uniqueidcheck <- data3_cleanweight1 %>%
group_by(personid) %>%
mutate(duplicate_name = n()-1)
# All ID's are unique!
skewness(data3_cleanweight1, na.rm = T)
vis_dat(data3_cleanweight1)
data4 <- data3_cleanweight1 %>%
select(-c(numadult, drvisits, mscode, income2, hlthcvr1)) %>%
filter(ageg5yr > 3) %>%
# The US Preventative Service Task Force recommends that screenings for diabetes should start at age 35, so we only include individuals 35 or older.
filter(diabete3 == 1 | diabete3 == 3) %>%
#We are not interested in anyone with gestational diabetes or prediabetic individuals because they are not official diabetes diagnoses. Even if we were interested in keeping gestational diabetes or prediabetes as covariates, we could not use them because it is unknown of those respondents have type 2 diagnoses later.
mutate(diabete3 = case_when(diabete3 == 3 ~ 0,
TRUE ~ 1)) %>%
na.omit()
# After this modification, we have 3417 observations
data4_sample <- data4 %>%
group_by(race) %>%
mutate(Freq=n()) %>%
mutate(perc_total_respondents = Freq/3417*100) %>%
ungroup()
data4_sample$diabete3 <- factor(data4_sample$diabete3)
data4_sample$race <- factor(data4_sample$race)
data4_sample$sex <- factor(data4_sample$sex)
data4_sample$ageg5yr <- factor(data4_sample$ageg5yr)
data4_sample$bmi5cat <- factor(data4_sample$bmi5cat)
data4_sample$smoker3 <- factor(data4_sample$smoker3)
data4_sample$addepev2 <- factor(data4_sample$addepev2)
data4_sample$cvdcrhd4 <- factor(data4_sample$cvdcrhd4)
data4_sample$chckidny <- factor(data4_sample$chckidny)
data4_sample$totinda <- factor(data4_sample$totinda)
data4_sample$genhlth <- factor(data4_sample$genhlth)
data4_sample$employ1 <- factor(data4_sample$employ1)
data4_sample$useequip <- factor(data4_sample$useequip)
data4_sample$asthma3 <- factor(data4_sample$asthma3)
data4_sample$hlthpln1 <- factor(data4_sample$hlthpln1)
data4_sample$decide <- factor(data4_sample$decide)
data4_sample$blind <- factor(data4_sample$blind)
data4_sample$exerany2 <- factor(data4_sample$exerany2)
prop.table(table(data4_sample$diabete3))
data4_sample$cvdcrhd4 <- as.factor(data4_sample$cvdcrhd4)
heartdisease_hist <- ggplot(data4_sample) + geom_histogram(aes(x=cvdcrhd4), stat='count')
boruta_data <- data4_sample %>%
select(-c(Freq, perc_total_respondents, personid,weight_correct))
#Omit varialbes that we don't intend on using in our model
#boruta_train <- Boruta(diabete3~., data = boruta_data)
# Confirmed, non-tentative: The following variables are predictive and should be kept.
# children, genhlth, ageg5yr,bmi5cat, educag, sleptim1, menthlth, race, employ1, cvdcrhd4, chckidny, useequip, addepev2, exerany2, decide, marital, sex
# Tentative. The algorithm was indecisive about if these are predictive. It is up to us to include.
# checkup1, smoker3, totinda
model.matrix(~0+.-Freq-perc_total_respondents-personid-state, data=data4_sample) %>%
cor(use="pairwise.complete.obs") %>%
ggcorrplot(show.diag = F, type="lower", lab=TRUE, lab_size=2)
# Given the figure, omit totinda
# No physical activity in the past 30 days is 100% correlated with no physical exercise in the past 30 days. Because totinda is a tentative attribute according to the Boruta algorithm, we opt to use exerany.
children_hist <- ggplot(data4_sample, aes(x=children)) + geom_histogram()
genhlth_hist <- ggplot(data4_sample, aes(x=genhlth)) + geom_bar() + labs(y="Count", x = "Gen. Health Category")
ageg5yr_hist <- ggplot(data4_sample, aes(x=ageg5yr)) + geom_bar() + labs(y="Count", x = "Age Category")
bmi5cat_hist <- ggplot(data4_sample, aes(x=bmi5cat)) + geom_bar() + labs(y="Count", x = "BMI Category")
checkup_hist <- ggplot(data4_sample, aes(x=checkup1)) + geom_bar()
educag_hist <- ggplot(data4_sample, aes(x=educag)) + geom_bar()+
scale_x_discrete(breaks=c(1, 2, 3, 4, 5, 6, 7, 8, 9))
sleptim_hist <- ggplot(data4_sample, aes(x=sleptim1)) + geom_histogram(bins=30) + labs(y="Count", x = "Hours Slept/24 Hours")
menthlth_hist <- ggplot(data4_sample, aes(x=menthlth)) + geom_histogram(bins=45) + labs(y="Count", x = "# Poor Mental Health Days in the Past Month")
employ1_hist <- ggplot(data4_sample, aes(x=employ1)) + geom_bar()
race_hist <- ggplot(data4_sample, aes(x=race)) + geom_bar() + labs(y="Count", x = "Race")
cvdcrhd4_table <- table(data4_sample$cvdcrhd4)
cvdcrhd4_hist <- ggplot(data4_sample) + geom_bar(aes(x=cvdcrhd4)) + labs(y="Count", x = "Chronic Heart Disease? (Y/N")
chckidny_table <- table(data4_sample$chckidny)
chckidny_hist <- ggplot(data4_sample) + geom_bar(aes(x=chckidny)) + labs(y="Count", x = "Kidney Disease? (Y/N")
useequip_table <- table(data4_sample$useequip)
addepev2_table <- table(data4_sample$addepev2)
addepev2_hist <- ggplot(data4_sample) + geom_bar(aes(x=addepev2)) + labs(y="Count", x = "Depressive Disorder? (Y/N)")
exerany_table <- table(data4_sample$exerany2)
exerany_hist <- ggplot(data4_sample) + geom_bar(aes(x=exerany2)) + labs(y="Count", x = "Exercise in the Past Month (Y/N)")
decide_table <- table(data4_sample$decide)
marital_hist <- ggplot(data4_sample, aes(x=marital)) + geom_bar() + labs(y="Count", x = "Marital Status")
sex_table <- table(data4_sample$sex)
smoker3_hist <- ggplot(data4_sample, aes(x=smoker3)) + geom_bar() + labs(y="Count", x = "Smoker Status")
sex_hist <- ggplot(data4_sample) + geom_bar(aes(x=sex)) + labs(y="Count", x = "Sex")
sd(data4_sample$menthlth)
mean(data4_sample$menthlth)
relevant_vars <- grid.arrange(bmi5cat_hist, ageg5yr_hist, race_hist, sex_hist, menthlth_hist, addepev2_hist,
sleptim_hist, exerany_hist, smoker3_hist, cvdcrhd4_hist, chckidny_hist,
ncol=4, nrow =3)
ggsave("/Users/snerbs/Desktop/GitHub/DigitalCorpsApp/relevant_vars",
relevant_vars,
device = png,
width=10,
height=10
)
train <- data4_sample %>%
dplyr::sample_frac(0.75)
prop.table(table(train$diabete3))
# Creating test sample-- still need to create a racially representative sample here as well before testing the model we created
test  <- dplyr::anti_join(data4_sample, train, by = 'personid')
prop.table(table(test$diabete3))
mylogit <- glm(diabete3 ~children+genhlth+ageg5yr+bmi5cat+checkup1+educag+sleptim1+menthlth+race+employ1+cvdcrhd4+chckidny+useequip+addepev2+exerany2+decide+marital+sex+smoker3, data = train, family = binomial(link = "logit"))
anova_logit <- anova(mylogit, test="Chisq")
# Use a chi-squared test because we have a lot of categorical and ordinal variables. The p values we have in the regression output correspond to individual Wald tests, but those p values do not tell us if the entire categorical/ordinal variable) explains the probability of getting diabetes. We have to test the coefficients together, so we perform a deviance goodness of fit test.
summary(mylogit)
anova_logit
# How to interpret this test: rejecting the null means the reduction in deviance is larger than one would expect if a variable did not explain anything about the outcome
probabilities <- mylogit %>% predict(test, type = "response")
# The result is continuous values of probabilities of diabetes occurrence, but we are interested in predicting if someone will have diabetes or not. If anyone has a probability above 50%, we assume that they will be diagnosed with diabetes.
predicted_classes <- ifelse(probabilities > 0.5, 1, 0)
# Take the predictions and append as a column to the test dataframe to create a confusion matrix
# Do do that, we must first converting predicted classes to a dataframe
predicted_classes_logit <- as.data.frame(predicted_classes)
test_predicted_logit <- cbind(predicted_classes_logit, test)
logitconfusionmatrix <-confusionMatrix(data=as.factor(test_predicted_logit$predicted_classes), reference=as.factor(test_predicted_logit$diabete3))
logitconfusionmatrix
BrierScore(mylogit)
# create roc curve
roc_logit <- roc(test_predicted_logit$diabete3, test_predicted_logit$predicted_classes)
# calculate area under curve
auc_logit <- auc(roc_logit)
auc_logit
decisiontree <- rpart(diabete3 ~children+genhlth+ageg5yr+bmi5cat+checkup1+educag+sleptim1+menthlth+race+employ1+cvdcrhd4+chckidny+useequip+addepev2+exerany2+decide+marital+sex+smoker3, data = train, method='class')
rpart.plot(decisiontree)
predict_model<-predict(decisiontree, test, type='class')
predicted_classes_decisiontree <- as.data.frame(predict_model)
test_predicted_decisiontree <- cbind(predicted_classes_decisiontree, test)
decisiontree_confusionmatrix<-confusionMatrix(data=test_predicted_decisiontree$predict_model, reference=test_predicted_decisiontree$diabete3)
decisiontree_confusionmatrix
predict_model <- as.numeric(predict_model)
roc_object_decisiontree <- roc(test$diabete3, predict_model)
# Calculate area under curve, the closer this is to 1 the more useful the model is
auc_decisiontree <- auc(roc_object_decisiontree)
auc_decisiontree
rf <- randomForest(diabete3 ~children+genhlth+ageg5yr+bmi5cat+checkup1+educag+sleptim1+menthlth+race+employ1+cvdcrhd4+chckidny+useequip+addepev2+exerany2+decide+marital+sex+smoker3, data=train, proximity=TRUE, ntree=500)
plot(rf)
pred_randomforest_test <- predict(rf, newdata = test, type= "class")
test_predicted_randomforest <- cbind(pred_randomforest_test, test)
confusionmatrixRandomForest <- confusionMatrix(data=as.factor(test_predicted_randomforest$pred_randomforest_test),
reference=as.factor(test_predicted_randomforest$diabete3))
confusionmatrixRandomForest
pred_randomforest_test <-  as.numeric(pred_randomforest_test)
# create roc curve
roc_object_randomforests <- roc(test$diabete3, pred_randomforest_test)
# calculate area under curve
auc_randomforests <- auc(roc_object_randomforests)
auc_randomforests
full_sample_logit <- mylogit %>% predict(data4_sample, type = "response")
predicted_classes_final <- ifelse(full_sample_logit > 0.5, 1, 0)
predicted_classes_logit_final <- as.data.frame(predicted_classes_final)
final_predicted_logit <- cbind(predicted_classes_logit, data4_sample)
final_predicted_logit <- cbind(predicted_classes_logit_final, data4_sample)
logitconfusionmatrix <-confusionMatrix(data=as.factor(final_predicted_logit$predicted_classes), reference=as.factor(final_predicted_logit$diabete3))
mylogit_final <- glm(diabete3 ~children+genhlth+ageg5yr+bmi5cat+checkup1+educag+sleptim1+menthlth+race+employ1+cvdcrhd4+chckidny+useequip+addepev2+exerany2+decide+marital+sex+smoker3, data = data4_sample, family = binomial(link = "logit"))
anova_logit_final <- anova(mylogit, test="Chisq")
summary(mylogit_final)
anova_logit_final
probabilities_final <- mylogit_final %>% predict(test, type = "response")
predicted_classes_final <- ifelse(probabilities_final > 0.5, 1, 0)
# Take the predictions and append as a column to the test dataframe to create a confusion matrix
# Do do that, we must first converting predicted classes to a dataframe
predicted_classes_logit_final <- as.data.frame(predicted_classes_final)
final_predicted_logit <- cbind(predicted_classes_logit_final, data4_sample)
probabilities_final <- mylogit_final %>% predict(data4_sample, type = "response")
predicted_classes_final <- ifelse(probabilities_final > 0.5, 1, 0)
# Take the predictions and append as a column to the test dataframe to create a confusion matrix
# Do do that, we must first converting predicted classes to a dataframe
predicted_classes_logit_final <- as.data.frame(predicted_classes_final)
final_predicted_logit <- cbind(predicted_classes_logit_final, data4_sample)
logitconfusionmatrix_final <-confusionMatrix(data=as.factor(final_predicted_logit$predicted_classes), reference=as.factor(predicted_classes_logit_final$diabete3))
View(final_predicted_logit)
logitconfusionmatrix_final <-confusionMatrix(data=as.factor(final_predicted_logit$predicted_classes_final), reference=as.factor(predicted_classes_logit_final$diabete3))
logitconfusionmatrix_final <-confusionMatrix(data=as.factor(final_predicted_logit$predicted_classes_final), reference=as.factor(final_predicted_logit$diabete3))
logitconfusionmatrix
# create roc curve
roc_logit_final <- roc(final_predicted_logit$diabete3, final_predicted_logit$predicted_classes_final)
# calculate area under curve
auc_logit_final <- auc(roc_logit_final)
auc_auc_logit_final
# calculate area under curve
auc_logit_final <- auc(roc_logit_final)
auc_logit_final
summary(mylogit_final)
