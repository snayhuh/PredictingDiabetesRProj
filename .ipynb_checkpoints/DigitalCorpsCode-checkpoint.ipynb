{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# United States Digital Corps Project-Based Assessment\n",
    "\n",
    "### Track: Data Science\n",
    "\n",
    "``` r\n",
    "knitr::opts_chunk$set(echo = TRUE)\n",
    "### Importing libraries \n",
    "library(dplyr, warn.conflicts = FALSE)\n",
    "library(tidyr)\n",
    "library(tidyverse)\n",
    "```\n",
    "\n",
    "    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n",
    "    ## ✔ ggplot2 3.4.0     ✔ purrr   1.0.0\n",
    "    ## ✔ tibble  3.1.8     ✔ stringr 1.5.0\n",
    "    ## ✔ readr   2.1.3     ✔ forcats 0.5.2\n",
    "    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
    "    ## ✖ dplyr::filter() masks stats::filter()\n",
    "    ## ✖ dplyr::lag()    masks stats::lag()\n",
    "\n",
    "``` r\n",
    "library(tidylog, warn.conflicts = FALSE)\n",
    "library(visdat)\n",
    "library(naniar)\n",
    "library(cdlTools)\n",
    "library(pROC)\n",
    "```\n",
    "\n",
    "    ## Type 'citation(\"pROC\")' for a citation.\n",
    "    ## \n",
    "    ## Attaching package: 'pROC'\n",
    "    ## \n",
    "    ## The following objects are masked from 'package:stats':\n",
    "    ## \n",
    "    ##     cov, smooth, var\n",
    "\n",
    "``` r\n",
    "library(caret)\n",
    "```\n",
    "\n",
    "    ## Loading required package: lattice\n",
    "    ## \n",
    "    ## Attaching package: 'caret'\n",
    "    ## \n",
    "    ## The following object is masked from 'package:purrr':\n",
    "    ## \n",
    "    ##     lift\n",
    "\n",
    "``` r\n",
    "library(e1071)\n",
    "library(Boruta)\n",
    "library(Rcpp)\n",
    "library(randomForest)\n",
    "```\n",
    "\n",
    "    ## randomForest 4.7-1.1\n",
    "    ## Type rfNews() to see new features/changes/bug fixes.\n",
    "    ## \n",
    "    ## Attaching package: 'randomForest'\n",
    "    ## \n",
    "    ## The following object is masked from 'package:ggplot2':\n",
    "    ## \n",
    "    ##     margin\n",
    "    ## \n",
    "    ## The following object is masked from 'package:dplyr':\n",
    "    ## \n",
    "    ##     combine\n",
    "\n",
    "``` r\n",
    "library(ROSE)\n",
    "```\n",
    "\n",
    "    ## Loaded ROSE 0.0-4\n",
    "\n",
    "``` r\n",
    "library(ggcorrplot)\n",
    "library(party)\n",
    "```\n",
    "\n",
    "    ## Loading required package: grid\n",
    "    ## Loading required package: mvtnorm\n",
    "    ## Loading required package: modeltools\n",
    "    ## Loading required package: stats4\n",
    "    ## Loading required package: strucchange\n",
    "    ## Loading required package: zoo\n",
    "    ## \n",
    "    ## Attaching package: 'zoo'\n",
    "    ## \n",
    "    ## The following objects are masked from 'package:base':\n",
    "    ## \n",
    "    ##     as.Date, as.Date.numeric\n",
    "    ## \n",
    "    ## Loading required package: sandwich\n",
    "    ## \n",
    "    ## Attaching package: 'strucchange'\n",
    "    ## \n",
    "    ## The following object is masked from 'package:stringr':\n",
    "    ## \n",
    "    ##     boundary\n",
    "\n",
    "``` r\n",
    "library(gridExtra)\n",
    "```\n",
    "\n",
    "    ## \n",
    "    ## Attaching package: 'gridExtra'\n",
    "    ## \n",
    "    ## The following object is masked from 'package:randomForest':\n",
    "    ## \n",
    "    ##     combine\n",
    "    ## \n",
    "    ## The following object is masked from 'package:dplyr':\n",
    "    ## \n",
    "    ##     combine\n",
    "\n",
    "# Section 1: Cleaning/EDA\n",
    "\n",
    "## Importing and Merging Data\n",
    "\n",
    "``` r\n",
    "numeric <- read_csv(\"Data/data_numeric.csv\", show_col_types = T)\n",
    "```\n",
    "\n",
    "    ## Rows: 5000 Columns: 6\n",
    "    ## ── Column specification ────────────────────────────────────────────────────────\n",
    "    ## Delimiter: \",\"\n",
    "    ## dbl (6): PERSONID, DIABETE3, NUMADULT, CHILDREN, WEIGHT2, DRVISITS\n",
    "    ## \n",
    "    ## ℹ Use `spec()` to retrieve the full column specification for this data.\n",
    "    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
    "\n",
    "``` r\n",
    "spec(numeric)\n",
    "```\n",
    "\n",
    "    ## cols(\n",
    "    ##   PERSONID = col_double(),\n",
    "    ##   DIABETE3 = col_double(),\n",
    "    ##   NUMADULT = col_double(),\n",
    "    ##   CHILDREN = col_double(),\n",
    "    ##   WEIGHT2 = col_double(),\n",
    "    ##   DRVISITS = col_double()\n",
    "    ## )\n",
    "\n",
    "``` r\n",
    "categorical <- read_csv(\"Data/data_categorical.csv\", show_col_types = T)\n",
    "```\n",
    "\n",
    "    ## New names:\n",
    "    ## Rows: 5000 Columns: 23\n",
    "    ## ── Column specification\n",
    "    ## ──────────────────────────────────────────────────────── Delimiter: \",\" dbl\n",
    "    ## (23): PERSONID, DIABETE3...2, _RACE, MSCODE, FLUSHOT6, EMPLOY1, SEX, MAR...\n",
    "    ## ℹ Use `spec()` to retrieve the full column specification for this data. ℹ\n",
    "    ## Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
    "    ## • `DIABETE3` -> `DIABETE3...2`\n",
    "    ## • `MARITAL` -> `MARITAL...8`\n",
    "    ## • `DIABETE3` -> `DIABETE3...20`\n",
    "    ## • `MARITAL` -> `MARITAL...23`\n",
    "\n",
    "``` r\n",
    "spec(categorical)\n",
    "```\n",
    "\n",
    "    ## cols(\n",
    "    ##   PERSONID = col_double(),\n",
    "    ##   DIABETE3...2 = col_double(),\n",
    "    ##   `_RACE` = col_double(),\n",
    "    ##   MSCODE = col_double(),\n",
    "    ##   FLUSHOT6 = col_double(),\n",
    "    ##   EMPLOY1 = col_double(),\n",
    "    ##   SEX = col_double(),\n",
    "    ##   MARITAL...8 = col_double(),\n",
    "    ##   CVDCRHD4 = col_double(),\n",
    "    ##   HLTHCVR1 = col_double(),\n",
    "    ##   CHCKIDNY = col_double(),\n",
    "    ##   USEEQUIP = col_double(),\n",
    "    ##   `_TOTINDA` = col_double(),\n",
    "    ##   ADDEPEV2 = col_double(),\n",
    "    ##   RENTHOM1 = col_double(),\n",
    "    ##   EXERANY2 = col_double(),\n",
    "    ##   BLIND = col_double(),\n",
    "    ##   DECIDE = col_double(),\n",
    "    ##   HLTHPLN1 = col_double(),\n",
    "    ##   DIABETE3...20 = col_double(),\n",
    "    ##   `_STATE` = col_double(),\n",
    "    ##   ASTHMA3 = col_double(),\n",
    "    ##   MARITAL...23 = col_double()\n",
    "    ## )\n",
    "\n",
    "``` r\n",
    "ordinal <- read_csv(\"Data/data_ordinal.csv\", show_col_types = T)\n",
    "```\n",
    "\n",
    "    ## Rows: 5000 Columns: 11\n",
    "    ## ── Column specification ────────────────────────────────────────────────────────\n",
    "    ## Delimiter: \",\"\n",
    "    ## dbl (11): PERSONID, DIABETE3, GENHLTH, _AGEG5YR, _BMI5CAT, CHECKUP1, INCOME2...\n",
    "    ## \n",
    "    ## ℹ Use `spec()` to retrieve the full column specification for this data.\n",
    "    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
    "\n",
    "``` r\n",
    "spec(ordinal)\n",
    "```\n",
    "\n",
    "    ## cols(\n",
    "    ##   PERSONID = col_double(),\n",
    "    ##   DIABETE3 = col_double(),\n",
    "    ##   GENHLTH = col_double(),\n",
    "    ##   `_AGEG5YR` = col_double(),\n",
    "    ##   `_BMI5CAT` = col_double(),\n",
    "    ##   CHECKUP1 = col_double(),\n",
    "    ##   INCOME2 = col_double(),\n",
    "    ##   `_EDUCAG` = col_double(),\n",
    "    ##   SLEPTIM1 = col_double(),\n",
    "    ##   MENTHLTH = col_double(),\n",
    "    ##   `_SMOKER3` = col_double()\n",
    "    ## )\n",
    "\n",
    "``` r\n",
    "num_ord <- left_join(numeric, ordinal, \"PERSONID\")\n",
    "```\n",
    "\n",
    "    ## left_join: added 11 columns (DIABETE3.x, DIABETE3.y, GENHLTH, _AGEG5YR, _BMI5CAT, …)\n",
    "    ##            > rows only in x       0\n",
    "    ##            > rows only in y  (    0)\n",
    "    ##            > matched rows     5,000\n",
    "    ##            >                 =======\n",
    "    ##            > rows total       5,000\n",
    "\n",
    "``` r\n",
    "num_ord_cat <- left_join(num_ord, categorical, \"PERSONID\")\n",
    "```\n",
    "\n",
    "    ## left_join: added 22 columns (DIABETE3...2, _RACE, MSCODE, FLUSHOT6, EMPLOY1, …)\n",
    "    ##            > rows only in x       0\n",
    "    ##            > rows only in y  (    0)\n",
    "    ##            > matched rows     5,000\n",
    "    ##            >                 =======\n",
    "    ##            > rows total       5,000\n",
    "\n",
    "``` r\n",
    "spec(num_ord_cat)\n",
    "```\n",
    "\n",
    "    ## cols(\n",
    "    ##   PERSONID = col_double(),\n",
    "    ##   DIABETE3 = col_double(),\n",
    "    ##   NUMADULT = col_double(),\n",
    "    ##   CHILDREN = col_double(),\n",
    "    ##   WEIGHT2 = col_double(),\n",
    "    ##   DRVISITS = col_double()\n",
    "    ## )\n",
    "\n",
    "# Section 2: Cleaning and quality-checking data\n",
    "\n",
    "## Run data quality checks on columns that look to be identical\n",
    "\n",
    "``` r\n",
    "data1 <- num_ord_cat %>%\n",
    "  select(starts_with(\"DIABET\") | starts_with(\"MARITAL\")) %>%\n",
    "  mutate(DIABET3_diff = ifelse(DIABETE3.x == DIABETE3.y & \n",
    "                                 DIABETE3.x == `DIABETE3...2` &\n",
    "                                 DIABETE3.x == `DIABETE3...20`, 0, 1)) %>%\n",
    "  ## There are 10 NA values in the marital difference variable-- want to see if they are missing for the same observations\n",
    "  mutate(MARITAL_DIFF = ifelse((`MARITAL...8` == `MARITAL...23`) | \n",
    "                                 (is.na(`MARITAL...8`) & is.na(`MARITAL...23`)), 0 ,1)) \n",
    "```\n",
    "\n",
    "    ## select: dropped 32 variables (PERSONID, NUMADULT, CHILDREN, WEIGHT2, DRVISITS, …)\n",
    "\n",
    "    ## mutate: new variable 'DIABET3_diff' (double) with one unique value and 0% NA\n",
    "\n",
    "    ## mutate: new variable 'MARITAL_DIFF' (double) with one unique value and 0% NA\n",
    "\n",
    "## Take out duplicate columns and clean up variable names using janitor\n",
    "\n",
    "``` r\n",
    "data2 <- num_ord_cat %>%\n",
    "  select(-c(DIABETE3.y, `DIABETE3...2`, `DIABETE3...20`, `MARITAL...8`)) %>%\n",
    "  janitor::clean_names()\n",
    "```\n",
    "\n",
    "    ## select: dropped 4 variables (DIABETE3.y, DIABETE3...2, MARITAL...8, DIABETE3...20)\n",
    "\n",
    "## Account for NA and 0 values in data as provided by data documentation\n",
    "\n",
    "``` r\n",
    "data3 <- data2 %>%\n",
    "  replace_with_na(replace = list(weight2 = c(9999, 7777),\n",
    "                                 children = 99, \n",
    "                                 drvisits = c(77, 99),\n",
    "                                 income2 = c(77, 99),\n",
    "                                 checkup1 = c(7, 9), \n",
    "                                 sleptim1 = c(77, 99), \n",
    "                                 menthlth = c(77, 99), \n",
    "                                 diabete3_x = c(7, 9), \n",
    "                                 race = c(6, 9), \n",
    "                                 flushot6 = c(7, 9), \n",
    "                                 employ1 = 9, \n",
    "                                 marital_23 = 9, \n",
    "                                 cvdcrhd4 = c(7, 9), \n",
    "                                 hlthcvr1 = c(77, 99), \n",
    "                                 chckidny = c(7, 9), \n",
    "                                 useequip = c(7, 9),\n",
    "                                 totinda = 9, \n",
    "                                 addepev2 = c(7, 9),\n",
    "                                 renthom1 = c(7, 9),\n",
    "                                 exerany2 = c(7, 9),\n",
    "                                 blind = c(7, 9),\n",
    "                                 decide = c(7, 9),\n",
    "                                 hlthpln1 = c(7, 9), \n",
    "                                 genhlth = c(7, 9), \n",
    "                                 asthma3 = c(7, 9)))%>%\n",
    "  mutate(children = replace(children, children == 88, 0)) %>%\n",
    "  mutate(drvisits = replace(drvisits, drvisits == 88, 0)) %>%\n",
    "  mutate(menthlth = replace(menthlth, menthlth == 88, 0)) %>%\n",
    "  mutate(checkup1 = replace(checkup1, checkup1 == 88, 0)) %>%\n",
    "  mutate(marital = marital_23) %>%\n",
    "  mutate(diabete3 = diabete3_x) %>%\n",
    "  select(-c(marital_23, diabete3_x))\n",
    "```\n",
    "\n",
    "    ## mutate: changed 3,670 values (73%) of 'children' (0 new NA)\n",
    "\n",
    "    ## mutate: changed 351 values (7%) of 'drvisits' (0 new NA)\n",
    "\n",
    "    ## mutate: changed 3,454 values (69%) of 'menthlth' (0 new NA)\n",
    "\n",
    "    ## mutate: no changes\n",
    "\n",
    "    ## mutate: new variable 'marital' (double) with 7 unique values and 1% NA\n",
    "\n",
    "    ## mutate: new variable 'diabete3' (double) with 5 unique values and <1% NA\n",
    "\n",
    "    ## select: dropped 2 variables (diabete3_x, marital_23)\n",
    "\n",
    "## The documentation specifies that some weight values are in kilograms– convert all of them to pounds\n",
    "\n",
    "``` r\n",
    "data3_cleanweight1 <- data3 %>%\n",
    "  mutate(\n",
    "    weight_correct = case_when(\n",
    "      nchar(as.character(weight2))==4 ~ as.numeric(str_sub(weight2, -3)) * 2.20462,\n",
    "      TRUE ~ weight2\n",
    "    )) %>%\n",
    "  select(-weight2)\n",
    "```\n",
    "\n",
    "    ## mutate: new variable 'weight_correct' (double) with 230 unique values and 5% NA\n",
    "\n",
    "    ## select: dropped one variable (weight2)\n",
    "\n",
    "## Check for unique ID’s\n",
    "\n",
    "``` r\n",
    "uniqueidcheck <- data3_cleanweight1 %>% \n",
    "  group_by(personid) %>% \n",
    "  mutate(duplicate_name = n()-1)\n",
    "```\n",
    "\n",
    "    ## group_by: one grouping variable (personid)\n",
    "\n",
    "    ## mutate (grouped): new variable 'duplicate_name' (double) with one unique value and 0% NA\n",
    "\n",
    "``` r\n",
    "# All ID's are unique! \n",
    "```\n",
    "\n",
    "## Check missingness of data using vis_dat– sorts columns according to types of data\n",
    "\n",
    "``` r\n",
    "vis_dat(data3_cleanweight1)\n",
    "```\n",
    "\n",
    "    ## Warning: `gather_()` was deprecated in tidyr 1.2.0.\n",
    "    ## ℹ Please use `gather()` instead.\n",
    "    ## ℹ The deprecated feature was likely used in the visdat package.\n",
    "    ##   Please report the issue at <https://github.com/ropensci/visdat/issues>.\n",
    "\n",
    "<img src=\"attachment:vertopal_1f11af2b0886407fb3c3a304701a4c31/1473c573de381c615d4983e7adcab4e6abce083b.png\" width=\"672\" />\n",
    "\n",
    "## Omit variables with most missingness as indicated by visualization above\n",
    "\n",
    "### Given the data we have, we are interested in predicting cases of type 2 diabetes and assume that diabete3 captures type 2. Type 1 diabetes is a genetic condition that often shows up early in life, and type 2 is mainly lifestyle-related and develops over time.\n",
    "\n",
    "``` r\n",
    "data4 <- data3_cleanweight1 %>%\n",
    "  select(-c(numadult, drvisits, mscode, income2, hlthcvr1)) %>%\n",
    "  filter(ageg5yr > 2) %>%\n",
    "# The US Preventative Service Task Force recommends that screenings for diabetes should start at age 35, so we only include individuals 35 or older.  \n",
    "  filter(diabete3 == 1 | diabete3 == 3) %>%\n",
    "#We are not interested in anyone with gestational diabetes or prediabetic individuals because they are not official diabetes diagnoses. Even if we were interested in keeping gestational diabetes or prediabetes as covariates, we could not use them because it is unknown of those respondents have type 2 diagnoses later. \n",
    "  mutate(diabete3 = case_when(diabete3 == 3 ~ 0, \n",
    "         TRUE ~ 1)) %>%\n",
    "  na.omit()\n",
    "```\n",
    "\n",
    "    ## select: dropped 5 variables (numadult, drvisits, income2, mscode, hlthcvr1)\n",
    "\n",
    "    ## filter: removed 499 rows (10%), 4,501 rows remaining\n",
    "\n",
    "    ## filter: removed 116 rows (3%), 4,385 rows remaining\n",
    "\n",
    "    ## mutate: changed 3,764 values (86%) of 'diabete3' (0 new NA)\n",
    "\n",
    "``` r\n",
    "# After this modification, we have 3609 observations\n",
    "```\n",
    "\n",
    "## Check racial breakdown of data and assess if it is representative of nation\n",
    "\n",
    "``` r\n",
    "data4_sample <- data4 %>%\n",
    "  group_by(race) %>%\n",
    "  mutate(Freq=n()) %>%\n",
    "  mutate(perc_total_respondents = Freq/3808*100) %>%\n",
    "  # Compare perc_total_respondents with actual national racial breakdown using https://www.census.gov/content/dam/Census/library/publications/2015/demo/p25-1143.pdf page 9\n",
    "  # There are a disproportionate number of white respondents, which could potentially skew the sample \n",
    "  # We use weights to fix for heteroskedasticity AFTER establishing the training and test models because the representative-ness will change based on the random sample\n",
    "  ungroup()\n",
    "```\n",
    "\n",
    "    ## group_by: one grouping variable (race)\n",
    "\n",
    "    ## mutate (grouped): new variable 'Freq' (integer) with 7 unique values and 0% NA\n",
    "\n",
    "    ## mutate (grouped): new variable 'perc_total_respondents' (double) with 7 unique values and 0% NA\n",
    "\n",
    "    ## ungroup: no grouping variables\n",
    "\n",
    "# The following variables are categorical or ordinal. We need to convert the following objects to factors to represent that.\n",
    "\n",
    "``` r\n",
    "data4_sample$diabete3 <- factor(data4_sample$diabete3)\n",
    "data4_sample$race <- factor(data4_sample$race)\n",
    "data4_sample$sex <- factor(data4_sample$sex)\n",
    "data4_sample$ageg5yr <- factor(data4_sample$ageg5yr)\n",
    "data4_sample$bmi5cat <- factor(data4_sample$bmi5cat)\n",
    "data4_sample$smoker3 <- factor(data4_sample$smoker3)\n",
    "data4_sample$addepev2 <- factor(data4_sample$addepev2)\n",
    "data4_sample$cvdcrhd4 <- factor(data4_sample$cvdcrhd4)\n",
    "data4_sample$chckidny <- factor(data4_sample$chckidny)\n",
    "data4_sample$totinda <- factor(data4_sample$totinda)\n",
    "data4_sample$genhlth <- factor(data4_sample$genhlth)\n",
    "data4_sample$employ1 <- factor(data4_sample$employ1)\n",
    "data4_sample$useequip <- factor(data4_sample$useequip)\n",
    "data4_sample$asthma3 <- factor(data4_sample$asthma3)\n",
    "data4_sample$hlthpln1 <- factor(data4_sample$hlthpln1)\n",
    "data4_sample$decide <- factor(data4_sample$decide)\n",
    "data4_sample$blind <- factor(data4_sample$blind)\n",
    "data4_sample$exerany2 <- factor(data4_sample$exerany2)\n",
    "```\n",
    "\n",
    "# Before we start modeling, let’s check the distribution of diabetes\n",
    "\n",
    "``` r\n",
    "prop.table(table(data4_sample$diabete3))\n",
    "```\n",
    "\n",
    "    ## \n",
    "    ##         0         1 \n",
    "    ## 0.8614575 0.1385425\n",
    "\n",
    "##### Given the result above, I considered over and undersampling the data because of the 86/14 split on no diabetes/diabetes and was worried that the imbalance would skew the model. However, I decided against it for the following reasons:\n",
    "\n",
    "###### According to the National Diabetes Statistics Report (2014), 9.3% of the U.S. population has diabetes, meaning that we are not necessarily aiming for a 50/50 split and our sample is relatively representative of the US. Of the 9.3%, 27.8% are undiagnosed which our model aims to solve for. Because we are interested in accurate prediction and I believe the data is representative, we do not have to correct.\n",
    "\n",
    "###### There is a large risk of overfitting in the over-sampled model\n",
    "\n",
    "###### Under-sampling would reduce the sample and undermine its effectiveness\n",
    "\n",
    "###### The usefulness (AUC value) of the over, under, and non-sampled models would remain the same (or be very close to each other). This is because changing the class ratio only affects the intercept of a standard logistic regression model. It is a monotonic transformation of the log-odds. This also represents a monotonic function of the predicted probability values. Monotonic functions preserve order, and AUC stays the same with order meaning the AUC does not change.\n",
    "\n",
    "###### With our size sample, we have more than 600 observations in our minority class. Given that we can typically fit about 1 parameter per 15 members of the minority class without overfitting, we have enough flexibility in the sample.\n",
    "\n",
    "# Section 3.1: Model Selection:\n",
    "\n",
    "## Use the Boruta algorithm to see what variables are relevant in the data. Based on the earlier visualization, we omit numadult, drvisits, mscode, income2, and hlthcvr1 because they are largely missing from the data and we will not use them as predictors because of that.\n",
    "\n",
    "``` r\n",
    "boruta_data <- data4_sample %>%\n",
    "  select(-c(Freq, perc_total_respondents, personid,weight_correct))\n",
    "```\n",
    "\n",
    "    ## select: dropped 4 variables (personid, weight_correct, Freq, perc_total_respondents)\n",
    "\n",
    "``` r\n",
    "#Omit varialbes that we don't intend on using in our model\n",
    "boruta.train <- Boruta(diabete3~., data = boruta_data)\n",
    "# Confirmed, non-tentative: The following variables are predictive and should be kept.\n",
    "# children, genhlth, ageg5yr,bmi5cat, educag, sleptim1, menthlth, race, employ1, cvdcrhd4, chckidny, useequip, addepev2, exerany2, decide, marital, sex\n",
    "# Tentative. The algorithm was indecisive about if these are predictive. It is up to us to include. \n",
    "# checkup1, smoker3, totinda\n",
    "```\n",
    "\n",
    "## Create correlation plot for selected variables\n",
    "\n",
    "``` r\n",
    "model.matrix(~0+.-Freq-perc_total_respondents-personid-state, data=data4_sample) %>% \n",
    "     cor(use=\"pairwise.complete.obs\") %>% \n",
    "     ggcorrplot(show.diag = F, type=\"lower\", lab=TRUE, lab_size=2)\n",
    "```\n",
    "\n",
    "<img src=\"attachment:vertopal_1f11af2b0886407fb3c3a304701a4c31/7b3784012f391f2c71543eae4b31369e0b2bc0e4.png\" width=\"672\" />\n",
    "\n",
    "``` r\n",
    "# Given the figure, omit totinda \n",
    "# No physical activity in the past 30 days is 100% correlated with no physical exercise in the past 30 days. Because totinda is a tentative attribute according to the Boruta algorithm, we opt to use exerany. \n",
    "```\n",
    "\n",
    "# Section 3.2: Look into all of the variables specified by Boruta:\n",
    "\n",
    "``` r\n",
    "children_hist <- ggplot(data4_sample, aes(x=children)) + geom_histogram()\n",
    "genhlth_hist <- ggplot(data4_sample, aes(x=genhlth)) + geom_bar()\n",
    "ageg5yr_hist <- ggplot(data4_sample, aes(x=ageg5yr)) + geom_bar()\n",
    "bmi5cat_hist <- ggplot(data4_sample, aes(x=bmi5cat)) + geom_bar()\n",
    "checkup_hist <- ggplot(data4_sample, aes(x=checkup1)) + geom_bar()\n",
    "educag_hist <- ggplot(data4_sample, aes(x=educag)) + geom_bar()+\n",
    "  scale_x_discrete(breaks=c(1, 2, 3, 4, 5, 6, 7, 8, 9))\n",
    "sleptim_hist <- ggplot(data4_sample, aes(x=sleptim1)) + geom_histogram()\n",
    "menthlth_hist <- ggplot(data4_sample, aes(x=menthlth)) + geom_histogram(bins=45)\n",
    "employ1_hist <- ggplot(data4_sample, aes(x=employ1)) + geom_bar()\n",
    "cvdcrhd4_table <- table(data4_sample$cvdcrhd4)\n",
    "chckidny_table <- table(data4_sample$chckidny)\n",
    "useequip_table <- table(data4_sample$useequip)\n",
    "addepev2_table <- table(data4_sample$addepev2)\n",
    "exerany_table <- table(data4_sample$exerany2)\n",
    "decide_table <- table(data4_sample$decide)\n",
    "marital_hist <- ggplot(data4_sample, aes(x=marital)) + geom_bar()\n",
    "sex_table <- table(data4_sample$sex)\n",
    "smoker3_hist <- ggplot(data4_sample, aes(x=smoker3)) + geom_bar()\n",
    "totinda_table <- table(data4_sample$totinda)\n",
    "\n",
    "\n",
    "grid.arrange(children_hist, genhlth_hist, ageg5yr_hist, bmi5cat_hist, checkup_hist, educag_hist, sleptim_hist, menthlth_hist,employ1_hist, marital_hist, smoker3_hist, ncol=3, nrow =4)\n",
    "```\n",
    "\n",
    "    ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n",
    "    ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n",
    "\n",
    "<img src=\"attachment:vertopal_1f11af2b0886407fb3c3a304701a4c31/9c2b9572586899fc7ea70d795641274a6c9796f4.png\" width=\"672\" />\n",
    "\n",
    "# Section 3.3: Split the data into training and test sets before adjusting the samples.\n",
    "\n",
    "## We use the training data to test and validate the model then treat the test dataset as new data to evaluate how effective the model is. We will adjust the racial representative-ness of the sample in the training data. When we split the data into training and test sets, the data is randomly divided, meaning the training and/or test sets may have the same racial split as the lar\n",
    "\n",
    "``` r\n",
    "train <- data4_sample %>% \n",
    "  dplyr::sample_frac(0.75) %>%\n",
    "  group_by(race) %>%\n",
    "  mutate(perc_population = case_when(race == 1 ~  77.5,\n",
    "                                     race == 2 ~ 13.2,\n",
    "                                     race == 3 ~ 1.2, \n",
    "                                     race == 4 ~ 5.4, \n",
    "                                     race == 5 ~ 0.2, \n",
    "                                     race == 7 ~ 2.5, \n",
    "                         TRUE~15.3)) %>%\n",
    "  ## Used https://www.census.gov/content/dam/Census/library/publications/2015/demo/p25-1143.pdf page 9\n",
    "  ## subtracted 2.1 from the hispanic because we have 17.4 percent hispanic and that is not ONLY hispanic\n",
    "  mutate(race_weight = perc_population/perc_total_respondents) %>%\n",
    "  select(-c(perc_population, perc_total_respondents, Freq)) %>%\n",
    "  ungroup()\n",
    "```\n",
    "\n",
    "    ## group_by: one grouping variable (race)\n",
    "\n",
    "    ## mutate (grouped): new variable 'perc_population' (double) with 7 unique values and 0% NA\n",
    "\n",
    "    ## mutate (grouped): new variable 'race_weight' (double) with 7 unique values and 0% NA\n",
    "\n",
    "    ## select: dropped 3 variables (Freq, perc_total_respondents, perc_population)\n",
    "\n",
    "    ## ungroup: no grouping variables\n",
    "\n",
    "``` r\n",
    "prop.table(table(train$diabete3))\n",
    "```\n",
    "\n",
    "    ## \n",
    "    ##         0         1 \n",
    "    ## 0.8699668 0.1300332\n",
    "\n",
    "``` r\n",
    "# Creating test sample-- still need to create a racially representative sample here as well before testing the model we created\n",
    "test  <- dplyr::anti_join(data4_sample, train, by = 'personid') %>%\n",
    "  group_by(race) %>%\n",
    "  mutate(Freq=n()) %>%\n",
    "  mutate(perc_total_respondents = Freq/3808*100) %>%\n",
    "  mutate(perc_population = case_when(race == 1 ~  77.5,\n",
    "                                     race == 2 ~ 13.2,\n",
    "                                     race == 3 ~ 1.2, \n",
    "                                     race == 4 ~ 5.4, \n",
    "                                     race == 5 ~ 0.2, \n",
    "                                     race == 7 ~ 2.5, \n",
    "                         TRUE~15.3)) %>%\n",
    "  # Used https://www.census.gov/content/dam/Census/library/publications/2015/demo/p25-1143.pdf page 9\n",
    "  # subtracted 2.1 from the hispanic because we have 17.4 percent hispanic and that is not ONLY hispanic\n",
    "  mutate(race_weight = perc_population/perc_total_respondents) %>%\n",
    "  select(-c(perc_population, perc_total_respondents, Freq)) %>%\n",
    "  ungroup()\n",
    "```\n",
    "\n",
    "    ## group_by: one grouping variable (race)\n",
    "\n",
    "    ## mutate (grouped): changed 902 values (100%) of 'Freq' (0 new NA)\n",
    "\n",
    "    ## mutate (grouped): changed 902 values (100%) of 'perc_total_respondents' (0 new NA)\n",
    "\n",
    "    ## mutate (grouped): new variable 'perc_population' (double) with 7 unique values and 0% NA\n",
    "\n",
    "    ## mutate (grouped): new variable 'race_weight' (double) with 7 unique values and 0% NA\n",
    "\n",
    "    ## select: dropped 3 variables (Freq, perc_total_respondents, perc_population)\n",
    "\n",
    "    ## ungroup: no grouping variables\n",
    "\n",
    "``` r\n",
    "prop.table(table(test$diabete3))\n",
    "```\n",
    "\n",
    "    ## \n",
    "    ##         0         1 \n",
    "    ## 0.8359202 0.1640798\n",
    "\n",
    "# Section 4: Deploying the logit model\n",
    "\n",
    "## Now that we have the following:\n",
    "\n",
    "### Clean data\n",
    "\n",
    "### Training/test sets,\n",
    "\n",
    "## We can use a logit model to predict if someone will be diagnosed with diabetes.\n",
    "\n",
    "## Run the regression and examine the results\n",
    "\n",
    "``` r\n",
    "mylogit <- glm(diabete3 ~children+genhlth+ageg5yr+bmi5cat+checkup1+educag+sleptim1+menthlth+race+employ1+cvdcrhd4+chckidny+useequip+addepev2+exerany2+decide+marital+sex+smoker3, data = train, family = binomial(link = \"logit\"), weights = race_weight)\n",
    "```\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "``` r\n",
    "anova_logit <- anova(mylogit, test=\"Chisq\")\n",
    "```\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "    ## Warning in eval(family$initialize): non-integer #successes in a binomial glm!\n",
    "\n",
    "``` r\n",
    "# Use a chi-squared test because we have a lot of categorical and ordinal variables. The p values we have in the regression output correspond to individual Wald tests, but those p values do not tell us if the entire categorical/ordinal variable) explains the probability of getting diabetes. We have to test the coefficients together, so we perform a deviance goodness of fit test. \n",
    "```\n",
    "\n",
    "## View regression output\n",
    "\n",
    "``` r\n",
    "summary(mylogit)\n",
    "```\n",
    "\n",
    "    ## \n",
    "    ## Call:\n",
    "    ## glm(formula = diabete3 ~ children + genhlth + ageg5yr + bmi5cat + \n",
    "    ##     checkup1 + educag + sleptim1 + menthlth + race + employ1 + \n",
    "    ##     cvdcrhd4 + chckidny + useequip + addepev2 + exerany2 + decide + \n",
    "    ##     marital + sex + smoker3, family = binomial(link = \"logit\"), \n",
    "    ##     data = train, weights = race_weight)\n",
    "    ## \n",
    "    ## Deviance Residuals: \n",
    "    ##     Min       1Q   Median       3Q      Max  \n",
    "    ## -2.5451  -0.5499  -0.3078  -0.1280   4.6033  \n",
    "    ## \n",
    "    ## Coefficients:\n",
    "    ##              Estimate Std. Error z value Pr(>|z|)    \n",
    "    ## (Intercept) -5.968464   1.103556  -5.408 6.36e-08 ***\n",
    "    ## children     0.081073   0.080519   1.007 0.313993    \n",
    "    ## genhlth2     1.368731   0.339095   4.036 5.43e-05 ***\n",
    "    ## genhlth3     1.872357   0.331397   5.650 1.61e-08 ***\n",
    "    ## genhlth4     2.298294   0.345982   6.643 3.08e-11 ***\n",
    "    ## genhlth5     2.617605   0.393615   6.650 2.93e-11 ***\n",
    "    ## ageg5yr4     0.525956   0.817569   0.643 0.520018    \n",
    "    ## ageg5yr5     1.402070   0.738159   1.899 0.057510 .  \n",
    "    ## ageg5yr6     1.723306   0.733141   2.351 0.018744 *  \n",
    "    ## ageg5yr7     2.415389   0.703694   3.432 0.000598 ***\n",
    "    ## ageg5yr8     2.597914   0.709253   3.663 0.000249 ***\n",
    "    ## ageg5yr9     3.086862   0.708793   4.355 1.33e-05 ***\n",
    "    ## ageg5yr10    2.915876   0.717401   4.064 4.81e-05 ***\n",
    "    ## ageg5yr11    2.933734   0.726704   4.037 5.41e-05 ***\n",
    "    ## ageg5yr12    3.631177   0.733084   4.953 7.30e-07 ***\n",
    "    ## ageg5yr13    2.962661   0.738101   4.014 5.97e-05 ***\n",
    "    ## ageg5yr14    3.458971   1.090264   3.173 0.001511 ** \n",
    "    ## bmi5cat2    -0.045946   0.588672  -0.078 0.937788    \n",
    "    ## bmi5cat3     0.514411   0.580543   0.886 0.375571    \n",
    "    ## bmi5cat4     1.303108   0.578966   2.251 0.024401 *  \n",
    "    ## checkup1    -0.403097   0.099499  -4.051 5.09e-05 ***\n",
    "    ## educag      -0.057098   0.060650  -0.941 0.346487    \n",
    "    ## sleptim1     0.005765   0.037553   0.154 0.877989    \n",
    "    ## menthlth    -0.006718   0.008747  -0.768 0.442419    \n",
    "    ## race2        0.656545   0.172045   3.816 0.000136 ***\n",
    "    ## race3        0.437356   0.530508   0.824 0.409706    \n",
    "    ## race4       -0.032237   0.358710  -0.090 0.928391    \n",
    "    ## race5        2.503976   1.063410   2.355 0.018539 *  \n",
    "    ## race7        0.941334   0.323396   2.911 0.003605 ** \n",
    "    ## race8        0.773287   0.167745   4.610 4.03e-06 ***\n",
    "    ## employ12    -0.296660   0.275147  -1.078 0.280950    \n",
    "    ## employ13     0.637607   0.355514   1.793 0.072896 .  \n",
    "    ## employ14     0.131055   0.458392   0.286 0.774954    \n",
    "    ## employ15    -0.136460   0.315659  -0.432 0.665521    \n",
    "    ## employ16     2.024557   0.740146   2.735 0.006231 ** \n",
    "    ## employ17     0.157007   0.182264   0.861 0.389002    \n",
    "    ## employ18     0.286375   0.230385   1.243 0.213859    \n",
    "    ## cvdcrhd42   -0.663720   0.174852  -3.796 0.000147 ***\n",
    "    ## chckidny2   -0.275640   0.248827  -1.108 0.267967    \n",
    "    ## useequip2   -0.118756   0.159540  -0.744 0.456656    \n",
    "    ## addepev22   -0.393451   0.159867  -2.461 0.013850 *  \n",
    "    ## exerany22    0.016154   0.131068   0.123 0.901907    \n",
    "    ## decide2      0.471349   0.203607   2.315 0.020613 *  \n",
    "    ## marital      0.087514   0.042981   2.036 0.041740 *  \n",
    "    ## sex2        -0.197088   0.123220  -1.599 0.109712    \n",
    "    ## smoker32    -0.706187   0.381994  -1.849 0.064503 .  \n",
    "    ## smoker33     0.193401   0.222126   0.871 0.383929    \n",
    "    ## smoker34     0.173282   0.219062   0.791 0.428934    \n",
    "    ## smoker39     1.238588   0.737107   1.680 0.092892 .  \n",
    "    ## ---\n",
    "    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "    ## \n",
    "    ## (Dispersion parameter for binomial family taken to be 1)\n",
    "    ## \n",
    "    ##     Null deviance: 2664.2  on 2706  degrees of freedom\n",
    "    ## Residual deviance: 2029.6  on 2658  degrees of freedom\n",
    "    ## AIC: 2202.5\n",
    "    ## \n",
    "    ## Number of Fisher Scoring iterations: 7\n",
    "\n",
    "``` r\n",
    "anova_logit\n",
    "```\n",
    "\n",
    "    ## Analysis of Deviance Table\n",
    "    ## \n",
    "    ## Model: binomial, link: logit\n",
    "    ## \n",
    "    ## Response: diabete3\n",
    "    ## \n",
    "    ## Terms added sequentially (first to last)\n",
    "    ## \n",
    "    ## \n",
    "    ##          Df Deviance Resid. Df Resid. Dev  Pr(>Chi)    \n",
    "    ## NULL                      2706     2664.2              \n",
    "    ## children  1   43.756      2705     2620.4 3.720e-11 ***\n",
    "    ## genhlth   4  259.228      2701     2361.2 < 2.2e-16 ***\n",
    "    ## ageg5yr  11  109.165      2690     2252.0 < 2.2e-16 ***\n",
    "    ## bmi5cat   3   96.933      2687     2155.1 < 2.2e-16 ***\n",
    "    ## checkup1  1   21.884      2686     2133.2 2.897e-06 ***\n",
    "    ## educag    1    2.629      2685     2130.6   0.10494    \n",
    "    ## sleptim1  1    0.061      2684     2130.5   0.80536    \n",
    "    ## menthlth  1    0.835      2683     2129.7   0.36094    \n",
    "    ## race      6   39.764      2677     2089.9 5.068e-07 ***\n",
    "    ## employ1   7   14.333      2670     2075.6   0.04557 *  \n",
    "    ## cvdcrhd4  1   18.204      2669     2057.4 1.985e-05 ***\n",
    "    ## chckidny  1    1.722      2668     2055.6   0.18939    \n",
    "    ## useequip  1    0.618      2667     2055.0   0.43196    \n",
    "    ## addepev2  1    3.029      2666     2052.0   0.08177 .  \n",
    "    ## exerany2  1    0.001      2665     2052.0   0.97603    \n",
    "    ## decide    1    5.982      2664     2046.0   0.01445 *  \n",
    "    ## marital   1    2.991      2663     2043.0   0.08375 .  \n",
    "    ## sex       1    2.680      2662     2040.3   0.10164    \n",
    "    ## smoker3   4   10.712      2658     2029.6   0.03000 *  \n",
    "    ## ---\n",
    "    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "\n",
    "``` r\n",
    "# How to interpret this test: rejecting the null means the reduction in deviance is larger than one would expect if a variable did not explain anything about the outcome\n",
    "```\n",
    "\n",
    "## Section 4.1: Make predictions using test data\n",
    "\n",
    "``` r\n",
    "probabilities <- mylogit %>% predict(test, type = \"response\")\n",
    "# The result is continuous values of probabilities of diabetes occurrence, but we are interested in predicting if someone will have diabetes or not. If anyone has a probability above 50%, we assume that they will be diagnosed with diabetes.\n",
    "predicted_classes <- ifelse(probabilities > 0.5, 1, 0)\n",
    "```\n",
    "\n",
    "## Section 4.2: Evaluate the model by creating a confusion matrix\n",
    "\n",
    "``` r\n",
    "# Take the predictions and append as a column to the test dataframe to create a confusion matrix\n",
    "# Do do that, we must first converting predicted classes to a dataframe\n",
    "predicted_classes_logit <- as.data.frame(predicted_classes)\n",
    "test_predicted_logit <- cbind(predicted_classes_logit, test) \n",
    "logitconfusionmatrix <-confusionMatrix(data=as.factor(test_predicted_logit$predicted_classes), reference=as.factor(test_predicted_logit$diabete3))\n",
    "```\n",
    "\n",
    "``` r\n",
    "logitconfusionmatrix\n",
    "```\n",
    "\n",
    "    ## Confusion Matrix and Statistics\n",
    "    ## \n",
    "    ##           Reference\n",
    "    ## Prediction   0   1\n",
    "    ##          0 736 126\n",
    "    ##          1  18  22\n",
    "    ##                                           \n",
    "    ##                Accuracy : 0.8404          \n",
    "    ##                  95% CI : (0.8148, 0.8637)\n",
    "    ##     No Information Rate : 0.8359          \n",
    "    ##     P-Value [Acc > NIR] : 0.38            \n",
    "    ##                                           \n",
    "    ##                   Kappa : 0.1765          \n",
    "    ##                                           \n",
    "    ##  Mcnemar's Test P-Value : <2e-16          \n",
    "    ##                                           \n",
    "    ##             Sensitivity : 0.9761          \n",
    "    ##             Specificity : 0.1486          \n",
    "    ##          Pos Pred Value : 0.8538          \n",
    "    ##          Neg Pred Value : 0.5500          \n",
    "    ##              Prevalence : 0.8359          \n",
    "    ##          Detection Rate : 0.8160          \n",
    "    ##    Detection Prevalence : 0.9557          \n",
    "    ##       Balanced Accuracy : 0.5624          \n",
    "    ##                                           \n",
    "    ##        'Positive' Class : 0               \n",
    "    ## \n",
    "\n",
    "## Section 4.3: Create ROC Curve to calculate the performance of the classification model\n",
    "\n",
    "``` r\n",
    "roc_object <- roc(test$diabete3, probabilities)\n",
    "```\n",
    "\n",
    "    ## Setting levels: control = 0, case = 1\n",
    "\n",
    "    ## Setting direction: controls < cases\n",
    "\n",
    "``` r\n",
    "# Calculate area under curve, the closer this is to 1 the more useful the model is\n",
    "auc_logit <- auc(roc_object) \n",
    "auc_logit\n",
    "```\n",
    "\n",
    "    ## Area under the curve: 0.814\n",
    "\n",
    "# Section 5: Decision trees\n",
    "## Decision trees are graphic models of possible decisions and all related possible outcomes in a tree form, with the outcomes shown as \"branches\" off each choice\n",
    "\n",
    "``` r\n",
    "decisiontree <- ctree(diabete3 ~children+genhlth+ageg5yr+bmi5cat+checkup1+educag+sleptim1+menthlth+race+employ1+cvdcrhd4+chckidny+useequip+addepev2+exerany2+decide+marital+sex+smoker3, data = train)\n",
    "plot(decisiontree)\n",
    "```\n",
    "\n",
    "<img src=\"attachment:vertopal_1f11af2b0886407fb3c3a304701a4c31/8e983e30a06178d9e9a6788d715442a73a0159e3.png\" width=\"672\" />\n",
    "\n",
    "## Section 5.1: Make predictions using test data\n",
    "\n",
    "``` r\n",
    "predict_model<-predict(decisiontree, test)\n",
    "```\n",
    "\n",
    "## Section 5.2: Evaluate the model by creating a confusion matrix\n",
    "\n",
    "``` r\n",
    "predicted_classes_decisiontree <- as.data.frame(predict_model)\n",
    "test_predicted_decisiontree <- cbind(predicted_classes_decisiontree, test) \n",
    "\n",
    "decisiontree_confusionmatrix<-confusionMatrix(data=test_predicted_decisiontree$predict_model, reference=test_predicted_decisiontree$diabete3)\n",
    "```\n",
    "\n",
    "``` r\n",
    "decisiontree_confusionmatrix\n",
    "```\n",
    "\n",
    "    ## Confusion Matrix and Statistics\n",
    "    ## \n",
    "    ##           Reference\n",
    "    ## Prediction   0   1\n",
    "    ##          0 740 133\n",
    "    ##          1  14  15\n",
    "    ##                                           \n",
    "    ##                Accuracy : 0.837           \n",
    "    ##                  95% CI : (0.8113, 0.8606)\n",
    "    ##     No Information Rate : 0.8359          \n",
    "    ##     P-Value [Acc > NIR] : 0.4861          \n",
    "    ##                                           \n",
    "    ##                   Kappa : 0.1223          \n",
    "    ##                                           \n",
    "    ##  Mcnemar's Test P-Value : <2e-16          \n",
    "    ##                                           \n",
    "    ##             Sensitivity : 0.9814          \n",
    "    ##             Specificity : 0.1014          \n",
    "    ##          Pos Pred Value : 0.8477          \n",
    "    ##          Neg Pred Value : 0.5172          \n",
    "    ##              Prevalence : 0.8359          \n",
    "    ##          Detection Rate : 0.8204          \n",
    "    ##    Detection Prevalence : 0.9678          \n",
    "    ##       Balanced Accuracy : 0.5414          \n",
    "    ##                                           \n",
    "    ##        'Positive' Class : 0               \n",
    "    ## \n",
    "\n",
    "## Section 5.3: Create ROC Curve to calculate the performance of the classification model\n",
    "\n",
    "``` r\n",
    "predict_model <- as.numeric(predict_model)\n",
    "roc_object_decisiontree <- roc(test$diabete3, predict_model)\n",
    "```\n",
    "\n",
    "    ## Setting levels: control = 0, case = 1\n",
    "\n",
    "    ## Setting direction: controls < cases\n",
    "\n",
    "``` r\n",
    "# Calculate area under curve, the closer this is to 1 the more useful the model is\n",
    "auc_decisiontree <- auc(roc_object_decisiontree) \n",
    "auc_decisiontree\n",
    "```\n",
    "\n",
    "    ## Area under the curve: 0.5414\n",
    "\n",
    "# Section 6: Random Forests\n",
    "## Random Forests consist of a large number of individual decision trees that as an ensemble. Each individual tree in the random forest spits out a prediction and the category (in this case whether someone is diagnosed with diabetes) with the most votes becomes our model’s prediction\n",
    "\n",
    "``` r\n",
    "rf <- randomForest(diabete3 ~children+genhlth+ageg5yr+bmi5cat+checkup1+educag+sleptim1+menthlth+race+employ1+cvdcrhd4+chckidny+useequip+addepev2+exerany2+decide+marital+sex+smoker3, data=train, proximity=TRUE, ntree=500) \n",
    "plot(rf)\n",
    "```\n",
    "\n",
    "<img src=\"attachment:vertopal_1f11af2b0886407fb3c3a304701a4c31/04cf9f4935b8d5853e09f75929e7d6fcf916335b.png\" width=\"672\" />\n",
    "\n",
    "## Section 6.1: Make predictions using test data\n",
    "\n",
    "``` r\n",
    "pred_randomforest_test <- predict(rf, newdata = test, type= \"class\")\n",
    "```\n",
    "\n",
    "## Section 6.2: Evaluate the model by creating a confusion matrix\n",
    "\n",
    "``` r\n",
    "test_predicted_randomforest <- cbind(pred_randomforest_test, test) \n",
    "\n",
    "confusionmatrixRandomForest <- confusionMatrix(data=as.factor(test_predicted_randomforest$pred_randomforest_test), \n",
    "                                               reference=as.factor(test_predicted_randomforest$diabete3))\n",
    "```\n",
    "\n",
    "``` r\n",
    "confusionmatrixRandomForest\n",
    "```\n",
    "\n",
    "    ## Confusion Matrix and Statistics\n",
    "    ## \n",
    "    ##           Reference\n",
    "    ## Prediction   0   1\n",
    "    ##          0 742 136\n",
    "    ##          1  12  12\n",
    "    ##                                           \n",
    "    ##                Accuracy : 0.8359          \n",
    "    ##                  95% CI : (0.8101, 0.8595)\n",
    "    ##     No Information Rate : 0.8359          \n",
    "    ##     P-Value [Acc > NIR] : 0.5219          \n",
    "    ##                                           \n",
    "    ##                   Kappa : 0.0982          \n",
    "    ##                                           \n",
    "    ##  Mcnemar's Test P-Value : <2e-16          \n",
    "    ##                                           \n",
    "    ##             Sensitivity : 0.98408         \n",
    "    ##             Specificity : 0.08108         \n",
    "    ##          Pos Pred Value : 0.84510         \n",
    "    ##          Neg Pred Value : 0.50000         \n",
    "    ##              Prevalence : 0.83592         \n",
    "    ##          Detection Rate : 0.82262         \n",
    "    ##    Detection Prevalence : 0.97339         \n",
    "    ##       Balanced Accuracy : 0.53258         \n",
    "    ##                                           \n",
    "    ##        'Positive' Class : 0               \n",
    "    ## \n",
    "\n",
    "## Section 6.3: Create ROC Curve to calculate the performance of the classification model\n",
    "\n",
    "``` r\n",
    "pred_randomforest_test <-  as.numeric(pred_randomforest_test)\n",
    "# create roc curve\n",
    "roc_object_randomforests <- roc(test$diabete3, pred_randomforest_test)\n",
    "```\n",
    "\n",
    "    ## Setting levels: control = 0, case = 1\n",
    "\n",
    "    ## Setting direction: controls < cases\n",
    "\n",
    "``` r\n",
    "# calculate area under curve\n",
    "auc_randomforests <- auc(roc_object_randomforests)\n",
    "auc_randomforests\n",
    "```\n",
    "\n",
    "    ## Area under the curve: 0.5326"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
